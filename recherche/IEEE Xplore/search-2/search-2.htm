<div class="row"><div class="col-md-12"><div class="panel panel-success"><div class="panel-heading "><h3 class="panel-title">Search-2</h3></div>
<table border=1 class="table table-striped table-bordered table-hover table-condensed">
<thead><tr><th title="Field #1">Document Title</th>
<th title="Field #2">Added</th>
<th title="Field #3">Issue</th>
</tr></thead>
<tbody><tr><td>Secure Signature-Based Authenticated Key Establishment Scheme for Future IoT Applications</td>
<td align="right">2017</td>
<td>Internet of Things (IoT) is a network of all devices that can be accessed through the Internet. These devices can be remotely accessed and controlled using existing network infrastructure, thus allowing a direct integration of computing systems with the physical world. This also reduces human involvement along with improving accuracy and efficiency, resulting in economic benefit. The devices in IoT facilitate the day-to-day life of people. However, the IoT has an enormous threat to security and privacy due to its heterogeneous and dynamic nature. Authentication is one of the most challenging security requirements in the IoT environment, where a user (external party) can directly access information from the devices, provided the mutual authentication between user and devices happens. In this paper, we present a new signature-based authenticated key establishment scheme for the IoT environment. The proposed scheme is tested for security with the help of the widely used Burrows-Abadi-Needham logic, informal security analysis, and also the formal security verification using the broadly accepted automated validation of Internet security protocols and applications tool. The proposed scheme is also implemented using the widely accepted NS2 simulator, and the simulation results demonstrate the practicability of the scheme. Finally, the proposed scheme provides more functionality features, and its computational and communication costs are also comparable with other existing approaches.</td>
</tr>
<tr><td>A Software Defined Fog Node Based Distributed Blockchain Cloud Architecture for IoT</td>
<td align="right">2018</td>
<td>The recent expansion of the Internet of Things (IoT) and the consequent explosion in the volume of data produced by smart devices have led to the outsourcing of data to designated data centers. However, to manage these huge data stores, centralized data centers, such as cloud storage cannot afford auspicious way. There are many challenges that must be addressed in the traditional network architecture due to the rapid growth in the diversity and number of devices connected to the internet, which is not designed to provide high availability, real-time data delivery, scalability, security, resilience, and low latency. To address these issues, this paper proposes a novel blockchain-based distributed cloud architecture with a software defined networking (SDN) enable controller fog nodes at the edge of the network to meet the required design principles. The proposed model is a distributed cloud architecture based on blockchain technology, which provides low-cost, secure, and on-demand access to the most competitive computing infrastructures in an IoT network. By creating a distributed cloud infrastructure, the proposed model enables cost-effective high-performance computing. Furthermore, to bring computing resources to the edge of the IoT network and allow low latency access to large amounts of data in a secure manner, we provide a secure distributed fog node architecture that uses SDN and blockchain techniques. Fog nodes are distributed fog computing entities that allow the deployment of fog services, and are formed by multiple computing resources at the edge of the IoT network. We evaluated the performance of our proposed architecture and compared it with the existing models using various performance measures. The results of our evaluation show that performance is improved by reducing the induced delay, reducing the response time, increasing throughput, and the ability to detect real-time attacks in the IoT network with low performance overheads.</td>
</tr>
<tr><td>Untraceable Sensor Movement in Distributed IoT Infrastructure</td>
<td align="right">2015</td>
<td>Recent advances in information and communication technologies and embedded systems have given rise to a new disruptive technology, the Internet of Things (IoTs). IoT allows people and objects in the physical world as well as data and virtual environments to interact with each other so as to create smart environments, such as smart transport systems, smart cities, smart health, and so on. However, IoT raises some important questions and also introduces new challenges for the security of systems and processes and the privacy of individuals, such as their location and movements and so on. In this paper, at first, we propose a distributed IoT system architecture. Subsequently, we propose an anonymous authentication scheme, which can ensure some of the notable properties, such as sensor anonymity, sensor untraceability, resistance to replay attacks, cloning attacks, and so on. It is argued that the proposed authentication scheme will be useful in many distributed IoT applications (such as radio-frequency identification-based IoT system, Biosensor-based IoT healthcare system, and so on), where the privacy of the sensor movement is greatly desirable.</td>
</tr>
<tr><td>Where Analog Meets Digital: Analog?to?Information Conversion and Beyond</td>
<td align="right">2015</td>
<td>Energy efficiency, long battery life, and low latency are key attributes of many emerging ultralow-power sensing and monitoring systems. Applications such as always-on reactive sensors for natural human-device interfaces, as well as multiple consumer and industrial applications for the Internet of Things (IoT), require ultralow-power designs beyond the promise of state-of-the art data converters. These devices demand a new approach to analog-digital system partitioning with the goal of significant overall reduction in energy consumption. Unlike most multimedia systems, many IoT applications require signal information extraction or signature extraction, rather than full reconstruction of the original sensed waveforms. Under these conditions, Nyquist rate sampling may no longer offer the optimal digitization scheme. Recent work on alternative sensor digitization strategies targets drastic sampling rate reductions in analog-to-digital conversion, while preserving the valuable relevant information (knowledge) present in the sensed signal. This article aims to give an overview of the emerging field of analog-to-information conversion in light of various sub-Nyquist sampling techniques recently appearing in literature,as well as to highlight some of the opportunities, challenges, and new applications such converters offer.</td>
</tr>
<tr><td>Deep Learning Based Approach for Bearing Fault Diagnosis</td>
<td align="right">2017</td>
<td>Bearing is one of the most critical components in most electrical and power drives. Effective bearing fault diagnosis is important for keeping the electrical and power drives safe and operating normally. In the age of Internet of Things and Industrial 4.0, massive real-time data are collected from bearing health monitoring systems. Mechanical big data have the characteristics of large volume, diversity, and high velocity. There are two major problems in using the existing methods for bearing fault diagnosis with big data. The features are manually extracted relying on much prior knowledge about signal processing techniques and diagnostic expertise, and the used models have shallow architectures, limiting their capability in fault diagnosis. Effectively mining features from big data and accurately identifying the bearing health conditions with new advanced methods have become new issues. This paper presents a deep learning-based approach for bearing fault diagnosis. The presented approach preprocesses sensor signals using short-time Fourier transform (STFT). Based on a simple spectrum matrix obtained by STFT, an optimized deep learning structure, large memory storage retrieval (LAMSTAR) neural network, is built to diagnose the bearing faults. Acoustic emission signals acquired from a bearing test rig are used to validate the presented method. The validation results show the accurate classification performance on various bearing faults under different working conditions. The performance of the presented method is also compared with other effective bearing fault diagnosis methods reported in the literature. The comparison results have shown that the presented method gives much better diagnostic performance, even at relatively low rotating speeds.</td>
</tr>
<tr><td>Mobile Unmanned Aerial Vehicles (UAVs) for Energy-Efficient Internet of Things Communications</td>
<td align="right">2017</td>
<td>In this paper, the efficient deployment and mobility of multiple unmanned aerial vehicles (UAVs), used as aerial base stations to collect data from ground Internet of Things (IoT) devices, are investigated. In particular, to enable reliable uplink communications for the IoT devices with a minimum total transmit power, a novel framework is proposed for jointly optimizing the 3D placement and the mobility of the UAVs, device-UAV association, and uplink power control. First, given the locations of active IoT devices at each time instant, the optimal UAVs&#39; locations and associations are determined. Next, to dynamically serve the IoT devices in a time-varying network, the optimal mobility patterns of the UAVs are analyzed. To this end, based on the activation process of the IoT devices, the time instances at which the UAVs must update their locations are derived. Moreover, the optimal 3D trajectory of each UAV is obtained in a way that the total energy used for the mobility of the UAVs is minimized while serving the IoT devices. Simulation results show that, using the proposed approach, the total-transmit power of the IoT devices is reduced by 45% compared with a case, in which stationary aerial base stations are deployed. In addition, the proposed approach can yield a maximum of 28% enhanced system reliability compared with the stationary case. The results also reveal an inherent tradeoff between the number of update times, the mobility of the UAVs, and the transmit power of the IoT devices. In essence, a higher number of updates can lead to lower transmit powers for the IoT devices at the cost of an increased mobility for the UAVs.</td>
</tr>
<tr><td>An Energy-Efficient Architecture for the Internet of Things (IoT)</td>
<td align="right">2017</td>
<td>Internet of things (IoT) is a smart technology that connects anything anywhere at any time. Such ubiquitous nature of IoT is responsible for draining out energy from its resources. Therefore, the energy efficiency of IoT resources has emerged as a major research issue. In this paper, an energy-efficien t architecture for IoT has been proposed, which consists of three layers, namely, sensing and control, information processing, and presentation. The architectural design allows the system to predict the sleep interval of sensors based upon their remaining battery level, their previous usage history, and quality of information required for a particular application. The predicted value can be used to boost the utilization of cloud resources by reprovisioning the allocated resources when the corresponding sensory nodes are in sleep mode. This mechanism allows the energy-efficient utilization of all the IoT resources. The experimental results show a significant amount of energy saving in the case of sensor nodes and improved resource utilization of cloud resources.</td>
</tr>
<tr><td>Fog Computing in Healthcare–A Review and Discussion</td>
<td align="right">2017</td>
<td>Fog computing is an architectural style in which network components between devices and the cloud execute application-specific logic. We present the first review on fog computing within healthcare informatics, and explore, classify, and discuss different application use cases presented in the literature. For that, we categorize applications into use case classes and list an inventory of application-specific tasks that can be handled by fog computing. We discuss on which level of the network such fog computing tasks can be executed, and provide tradeoffs with respect to requirements relevant to healthcare. Our review indicates that: 1) there is a significant number of computing tasks in healthcare that require or can benefit from fog computing principles; 2) processing on higher network tiers is required due to constraints in wireless devices and the need to aggregate data; and 3) privacy concerns and dependability prevent computation tasks to be completely moved to the cloud. These findings substantiate the need for a coherent approach toward fog computing in healthcare, for which we present a list of recommended research and development actions.</td>
</tr>
<tr><td>Publish/subscribe-enabled software defined networking for efficient and scalable IoT communications</td>
<td align="right">2015</td>
<td>The Internet of Things (IoT) is the result of many different enabling technologies such as embedded systems, wireless sensor networks, cloud computing, big-data, etc., which are used to gather, process, infer, and transmit data. Combining all these technologies requires a research effort to address all the challenges of these technologies, especially for sensing and delivering information from the physical world to cloud-hosted services. In this article we outline the most important issues related to standardization efforts, mobility of objects, networking and gateway access, and QoS support. In particular, we describe a novel IoT network architecture that integrates software defined networking (SDN) and data distribution service (DDS) middleware. The proposed architecture will improve service delivery of IoT systems and will bring flexibility to the network.</td>
</tr>
<tr><td>A Deep Learning Approach to on-Node Sensor Data Analytics for Mobile or Wearable Devices</td>
<td align="right">2017</td>
<td>The increasing popularity of wearable devices in recent years means that a diverse range of physiological and functional data can now be captured continuously for applications in sports, wellbeing, and healthcare. This wealth of information requires efficient methods of classification and analysis where deep learning is a promising technique for large-scale data analytics. While deep learning has been successful in implementations that utilize high-performance computing platforms, its use on low-power wearable devices is limited by resource constraints. In this paper, we propose a deep learning methodology, which combines features learned from inertial sensor data together with complementary information from a set of shallow features to enable accurate and real-time activity classification. The design of this combined method aims to overcome some of the limitations present in a typical deep learning framework where on-node computation is required. To optimize the proposed method for real-time on-node computation, spectral domain preprocessing is used before the data are passed onto the deep learning framework. The classification accuracy of our proposed deep learning approach is evaluated against state-of-the-art methods using both laboratory and real world activity datasets. Our results show the validity of the approach on different human activity datasets, outperforming other methods, including the two methods used within our combined pipeline. We also demonstrate that the computation times for the proposed method are consistent with the constraints of real-time on-node processing on smartphones and a wearable sensor platform.</td>
</tr>
<tr><td>An IoT Endpoint System-on-Chip for Secure and Energy-Efficient Near-Sensor Analytics</td>
<td align="right">2017</td>
<td>Near-sensor data analytics is a promising direction for internet-of-things endpoints, as it minimizes energy spent on communication and reduces network load - but it also poses security concerns, as valuable data are stored or sent over the network at various stages of the analytics pipeline. Using encryption to protect sensitive data at the boundary of the on-chip analytics engine is a way to address data security issues. To cope with the combined workload of analytics and encryption in a tight power envelope, we propose Fulmine, a system-on-chip (SoC) based on a tightly-coupled multi-core cluster augmented with specialized blocks for compute-intensive data processing and encryption functions, supporting software programmability for regular computing tasks. The Fulmine SoC, fabricated in 65-nm technology, consumes less than 20mW on average at 0.8V achieving an efficiency of up to 70pJ/B in encryption, 50pJ/px in convolution, or up to 25MIPS/mW in software. As a strong argument for real-life flexible application of our platform, we show experimental results for three secure analytics use cases: secure autonomous aerial surveillance with a state-of-the-art deep convolutional neural network (CNN) consuming 3.16pJ per equivalent reduced instruction set computer operation, local CNN-based face detection with secured remote recognition in 5.74pJ/op, and seizure detection with encrypted data collection from electroencephalogram within 12.7pJ/op.</td>
</tr>
<tr><td>Fast Multiclass Dictionaries Learning With Geometrical Directions in MRI Reconstruction</td>
<td align="right">2016</td>
<td>Objective: Improve the reconstructed image with fast and multiclass dictionaries learning when magnetic resonance imaging is accelerated by undersampling the k-space data. Methods: A fast orthogonal dictionary learning method is introduced into magnetic resonance image reconstruction to provide adaptive sparse representation of images. To enhance the sparsity, image is divided into classified patches according to the same geometrical direction and dictionary is trained within each class. A new sparse reconstruction model with the multiclass dictionaries is proposed and solved using a fast alternating direction method of multipliers. Results: Experiments on phantom and brain imaging data with acceleration factor up to 10 and various undersampling patterns are conducted. The proposed method is compared with state-of-the-art magnetic resonance image reconstruction methods. Conclusion: Artifacts are better suppressed and image edges are better preserved than the compared methods. Besides, the computation of the proposed approach is much faster than the typical K-SVD dictionary learning method in magnetic resonance image reconstruction. Significance: The proposed method can be exploited in undersampled magnetic resonance imaging to reduce data acquisition time and reconstruct images with better image quality.</td>
</tr>
<tr><td>Near-Threshold RISC-V Core With DSP Extensions for Scalable IoT Endpoint Devices</td>
<td align="right">2017</td>
<td>Endpoint devices for Internet-of-Things not only need to work under extremely tight power envelope of a few milliwatts, but also need to be flexible in their computing capabilities, from a few kOPS to GOPS. Near-threshold (NT) operation can achieve higher energy efficiency, and the performance scalability can be gained through parallelism. In this paper, we describe the design of an open-source RISC-V processor core specifically designed for NT operation in tightly coupled multicore clusters. We introduce instruction extensions and microarchitectural optimizations to increase the computational density and to minimize the pressure toward the shared-memory hierarchy. For typical data-intensive sensor processing workloads, the proposed core is, on average, 3.5× faster and 3.2× more energy efficient, thanks to a smart L0 buffer to reduce cache access contentions and support for compressed instructions. Single Instruction Multiple Data extensions, such as dot products, and a built-in L0 storage further reduce the shared-memory accesses by 8× reducing contentions by 3.2×. With four NT-optimized cores, the cluster is operational from 0.6 to 1.2 V, achieving a peak efficiency of 67 MOPS/mW in a low-cost 65-nm bulk CMOS technology. In a low-power 28-nm FD-SOI process, a peak efficiency of 193 MOPS/mW (40 MHz and 1 mW) can be achieved.</td>
</tr>
<tr><td>CityPulse: Large Scale Data Analytics Framework for Smart Cities</td>
<td align="right">2016</td>
<td>Our world and our lives are changing in many ways. Communication, networking, and computing technologies are among the most influential enablers that shape our lives today. Digital data and connected worlds of physical objects, people, and devices are rapidly changing the way we work, travel, socialize, and interact with our surroundings, and they have a profound impact on different domains, such as healthcare, environmental monitoring, urban systems, and control and management applications, among several other areas. Cities currently face an increasing demand for providing services that can have an impact on people&#39;s everyday lives. The CityPulse framework supports smart city service creation by means of a distributed system for semantic discovery, data analytics, and interpretation of large-scale (near-)real-time Internet of Things data and social media data streams. To goal is to break away from silo applications and enable cross-domain data integration. The CityPulse framework integrates multimodal, mixed quality, uncertain and incomplete data to create reliable, dependable information and continuously adapts data processing techniques to meet the quality of information requirements from end users. Different than existing solutions that mainly offer unified views of the data, the CityPulse framework is also equipped with powerful data analytics modules that perform intelligent data aggregation, event detection, quality assessment, contextual filtering, and decision support. This paper presents the framework, describes its components, and demonstrates how they interact to support easy development of custom-made applications for citizens. The benefits and the effectiveness of the framework are demonstrated in a use-case scenario implementation presented in this paper.</td>
</tr>
<tr><td>Privacy and Security in Internet of Things and Wearable Devices</td>
<td align="right">2015</td>
<td>Enter the nascent era of Internet of Things (IoT) and wearable devices, where small embedded devices loaded with sensors collect information from its surroundings, process it, and relay it to remote locations for further analysis. Albeit looking harmless, these nascent technologies raise security and privacy concerns. We pose the question of the possibility and effects of compromising such devices. Concentrating on the design flow of IoT and wearable devices, we discuss some common design practices and their implications on security and privacy. Two representatives from each category, the Google Nest Thermostat and the Nike+ Fuelband, are selected as examples on how current industry practices of security as an afterthought or an add-on affect the resulting device and the potential consequences to the user&#39;s security and privacy. We then discuss design flow enhancements, through which security mechanisms can efficiently be added into a device, vastly differing from traditional practices.</td>
</tr>
<tr><td>Projected Iterative Soft-Thresholding Algorithm for Tight Frames in Compressed Sensing Magnetic Resonance Imaging</td>
<td align="right">2016</td>
<td>Compressed sensing (CS) has exhibited great potential for accelerating magnetic resonance imaging (MRI). In CS-MRI, we want to reconstruct a high-quality image from very few samples in a short time. In this paper, we propose a fast algorithm, called projected iterative soft-thresholding algorithm (pISTA), and its acceleration pFISTA for CS-MRI image reconstruction. The proposed algorithms exploit sparsity of the magnetic resonance (MR) images under the redundant representation of tight frames. We prove that pISTA and pFISTA converge to a minimizer of a convex function with a balanced tight frame sparsity formulation. The pFISTA introduces only one adjustable parameter, the step size, and we provide an explicit rule to set this parameter. Numerical experiment results demonstrate that pFISTA leads to faster convergence speeds than the state-of-art counterpart does, while achieving comparable reconstruction errors. Moreover, reconstruction errors incurred by pFISTA appear insensitive to the step size.</td>
</tr>
<tr><td>Enabling the IoT Machine Age With 5G: Machine-Type Multicast Services for Innovative Real-Time Applications</td>
<td align="right">2016</td>
<td>The Internet of Things (IoT) will shortly be undergoing a major transformation from a sensor-driven paradigm to one that is heavily complemented by actuators, drones, and robots. The real-time situational awareness of such active systems requires sensed data to be transmitted in the uplink to edge-cloud, processed, and control instructions transmitted in the downlink. Since many of these applications will be mission critical, the most suitable connectivity family will be cellular due to the availability of licensed spectrum able to protect the offered communications service. However, while much focus in the past was on the uplink of machine-type communications, little attention has been paid to the end-to-end reliability, latency, and energy consumption comprising both up and downlinks. To address this gap, in this paper, we focus on the definition, design, and analysis of machine-type multicast service (MtMS). We discuss the different procedures that need to be redesigned for MtMS and we derive the most appropriate design drivers by analyzing different performance indicators, such as scalability, reliability, latency, and energy consumption. We also discuss the open issues to be considered in future research aimed at enhancing the capabilities of MtMS to support a wide variety of 5G IoT use cases.</td>
</tr>
<tr><td>Understanding Data Heterogeneity in the Context of Cyber-Physical Systems Integration</td>
<td align="right">2017</td>
<td>The current gradual adoption of the Industry 4.0 is the research trend that includes more intensive utilization of cyber-physical systems (CPSs). The computerization of manufacturing will bring many advantages but it is needed to face the heterogeneity problem during an integration of various CPSs for enabling this progress. In this paper, we describe various types of heterogeneity with emphasis to a semantic heterogeneity. The CPSs integration problem is classified into two different challenges. Next, we introduce the approach and the implementation of the semantic heterogeneity reduction with the focus on using Semantic Web technologies for a data integration. Then, the Big Data approach is described for facilitating the implementation. Finally, the possible solution is demonstrated on our proposed semantic Big Data historian.</td>
</tr>
<tr><td>Virtualization on Internet of Things Edge Devices With Container Technologies: A Performance Evaluation</td>
<td align="right">2017</td>
<td>Lightweight virtualization technologies have revolutionized the world of software development by introducing flexibility and innovation to this domain. Although the benefits introduced by these emerging solutions have been widely acknowledged in cloud computing, recent advances have led to the spread of such technologies in different contexts. As an example, the Internet of Things (IoT) and mobile edge computing benefit from container virtualization by exploiting the possibility of using these technologies not only in data centers but also on devices, which are characterized by fewer computational resources, such as single-board computers. This has led to a growing trend to more efficiently redesign the critical components of IoT/edge scenarios (e.g., gateways) to enable the concept of device virtualization. The possibility for efficiently deploying virtualized instances on single-board computers has already been addressed in recent studies; however, these studies considered only a limited number of devices and omitted important performance metrics from their empirical assessments. This paper seeks to fill this gap and to provide insights for future deployments through a comprehensive performance evaluation that aims to show the strengths and weaknesses of several low-power devices when handling container-virtualized instances.</td>
</tr>
<tr><td>Energy-Efficient Location and Activity-Aware On-Demand Mobile Distributed Sensing Platform for Sensing as a Service in IoT Clouds</td>
<td align="right">2015</td>
<td>The Internet of Things (IoT) envisions billions of sensors deployed around us and connected to the Internet, where the mobile crowd sensing technologies are widely used to collect data in different contexts of the IoT paradigm. Due to the popularity of Big Data technologies, processing and storing large volumes of data have become easier than ever. However, large-scale data management tasks still require significant amounts of resources that can be expensive regardless of whether they are purchased or rented (e.g., pay-as-you-go infrastructure). Further, not everyone is interested in such large-scale data collection and analysis. More importantly, not everyone has the financial and computational resources to deal with such large volumes of data. Therefore, a timely need exists for a cloud-integrated mobile crowd sensing platform that is capable of capturing sensors data, on-demand, based on conditions enforced by the data consumers. In this paper, we propose a context-aware, specifically, location and activity-aware mobile sensing platform called context-aware mobile sensor data engine (C-MOSDEN) for the IoT domain. We evaluated the proposed platform using three real-world scenarios that highlight the importance of selective sensing. The computational effectiveness and efficiency of the proposed platform are investigated and are used to highlight the advantages of context-aware selective sensing.</td>
</tr>
<tr><td>Big Data Privacy in the Internet of Things Era</td>
<td align="right">2015</td>
<td>Over the last few years, we&#39;ve seen a plethora of Internet of Things (IoT) solutions, products, and services make their way into the industry&#39;s marketplace. All such solutions will capture large amounts of data pertaining to the environment as well as their users. The IoT&#39;s objective is to learn more and better serve system users. Some IoT solutions might store data locally on devices (&quot;things&quot;), whereas others might store it in the cloud. The real value of collecting data comes through data processing and aggregation on a large scale, where new knowledge can be extracted. However, such procedures can lead to user privacy issues. This article discusses some of the main challenges of privacy in the IoT as well as opportunities for research and innovation. The authors also introduce some of the ongoing research efforts that address IoT privacy issues.</td>
</tr>
<tr><td>Semantic Reasoning for Context-Aware Internet of Things Applications</td>
<td align="right">2017</td>
<td>Acquiring knowledge from continuous and heterogeneous data streams is a prerequisite for Internet of Things (IoT) applications. Semantic technologies provide comprehensive tools and applicable methods for representing, integrating, and acquiring knowledge. However, resource-constraints, dynamics, mobility, scalability, and real-time requirements introduce challenges for applying these methods in IoT environments. We study how to utilize semantic IoT data for reasoning of actionable knowledge by applying state-of-the-art semantic technologies. For performing these studies, we have developed a semantic reasoning system operating in a realistic IoT environment. We evaluate the scalability of different reasoning approaches, including a single reasoner, distributed reasoners, mobile reasoners, and a hybrid of them. We evaluate latencies of reasoning introduced by different semantic data formats. We verify the capabilities of promising semantic technologies for IoT applications through comparing the scalability and real-time response of different reasoning approaches with various semantic data formats. Moreover, we evaluate different data aggregation strategies for integrating distributed IoT data for reasoning processes.</td>
</tr>
<tr><td>Internet of Things Based Energy Aware Smart Home Control System</td>
<td align="right">2016</td>
<td>The concept of smart home is widely favored, as it enhances the lifestyle of the residents involving multiple disciplines, i.e., lighting, security, and much more. As the smart home networks continue to grow in size and complexity, it is essential to address a handful among the myriads of challenges related to data loss due to the interference and efficient energy management. In this paper, we propose a smart home control system using a coordinator-based ZigBee networking. The working of the proposed system is three fold: smart interference control system controls the interference caused due to the co-existence of IEEE 802.11x-based wireless local area networks and wireless sensor networks; smart energy control system is developed to integrate sunlight with light source and optimizes the energy consumption of the household appliances by controlling the unnecessary energy demands; and smart management control system to efficiently control the operating time of the electronic appliances. The performance of the proposed smart home is testified through computer simulation. Simulation results show that the proposed smart home system is less affected by the interference and efficient in reducing the energy consumption of the appliances used in a smart home.</td>
</tr>
<tr><td>Edge Computing: Vision and Challenges</td>
<td align="right">2016</td>
<td>The proliferation of Internet of Things (IoT) and the success of rich cloud services have pushed the horizon of a new computing paradigm, edge computing, which calls for processing the data at the edge of the network. Edge computing has the potential to address the concerns of response time requirement, battery life constraint, bandwidth cost saving, as well as data safety and privacy. In this paper, we introduce the definition of edge computing, followed by several case studies, ranging from cloud offloading to smart home and city, as well as collaborative edge to materialize the concept of edge computing. Finally, we present several challenges and opportunities in the field of edge computing, and hope this paper will gain attention from the community and inspire more research in this direction.</td>
</tr>
<tr><td>Cascaded Collaborative Regression for Robust Facial Landmark Detection Trained Using a Mixture of Synthetic and Real Images With Dynamic Weighting</td>
<td align="right">2015</td>
<td>A large amount of training data is usually crucial for successful supervised learning. However, the task of providing training samples is often time-consuming, involving a considerable amount of tedious manual work. In addition, the amount of training data available is often limited. As an alternative, in this paper, we discuss how best to augment the available data for the application of automatic facial landmark detection. We propose the use of a 3D morphable face model to generate synthesized faces for a regression-based detector training. Benefiting from the large synthetic training data, the learned detector is shown to exhibit a better capability to detect the landmarks of a face with pose variations. Furthermore, the synthesized training data set provides accurate and consistent landmarks automatically as compared to the landmarks annotated manually, especially for occluded facial parts. The synthetic data and real data are from different domains; hence the detector trained using only synthesized faces does not generalize well to real faces. To deal with this problem, we propose a cascaded collaborative regression algorithm, which generates a cascaded shape updater that has the ability to overcome the difficulties caused by pose variations, as well as achieving better accuracy when applied to real faces. The training is based on a mix of synthetic and real image data with the mixing controlled by a dynamic mixture weighting schedule. Initially, the training uses heavily the synthetic data, as this can model the gross variations between the various poses. As the training proceeds, progressively more of the natural images are incorporated, as these can model finer detail. To improve the performance of the proposed algorithm further, we designed a dynamic multi-scale local feature extraction method, which captures more informative local features for detector training. An extensive evaluation on both controlled and uncontrolled face data sets demonstrates the merit of the proposed algorithm.</td>
</tr>
<tr><td>Bluetooth Low Energy in Dense IoT Environments</td>
<td align="right">2016</td>
<td>Bluetooth Low Energy was designed as a low-power alternative to classic Bluetooth. However, the use of BLE in dense Internet of Things deployments results in high collision rates and wasted energy. To alleviate some of this contention, we present opportunistic listening, an extension to BLE active mode targeting IoT deployments with large numbers of tags and small numbers of scanning devices. For dense deployments of passive advertising devices, we present the design of Smart LaBLEs (BLE-enabled, electronic, de-centralized hubs), which aggregate multiple advertisements across similar products in a retail environment.</td>
</tr>
<tr><td>Fog of Everything: Energy-Efficient Networked Computing Architectures, Research Challenges, and a Case Study</td>
<td align="right">2017</td>
<td>Fog computing (FC) and Internet of Everything (IoE) are two emerging technological paradigms that, to date, have been considered standing-alone. However, because of their complementary features, we expect that their integration can foster a number of computing and network-intensive pervasive applications under the incoming realm of the future Internet. Motivated by this consideration, the goal of this position paper is fivefold. First, we review the technological attributes and platforms proposed in the current literature for the standing-alone FC and IoE paradigms. Second, by leveraging some use cases as illustrative examples, we point out that the integration of the FC and IoE paradigms may give rise to opportunities for new applications in the realms of the IoE, Smart City, Industry 4.0, and Big Data Streaming, while introducing new open issues. Third, we propose a novel technological paradigm, the Fog of Everything (FoE) paradigm, that integrates FC and IoE and then we detail the main building blocks and services of the corresponding technological platform and protocol stack. Fourth, as a proof-of-concept, we present the simulated energy-delay performance of a small-scale FoE prototype, namely, the V-FoE prototype. Afterward, we compare the obtained performance with the corresponding one of a benchmark technological platform, e.g., the V-D2D one. It exploits only device-to-device links to establish inter-thing “ad hoc” communication. Last, we point out the position of the proposed FoE paradigm over a spectrum of seemingly related recent research projects.</td>
</tr>
<tr><td>Joint Range-Doppler-Angle Estimation for Intelligent Tracking of Moving Aerial Targets</td>
<td align="right">2018</td>
<td>In the new era of integrated computing with intelligent devices and system, moving aerial targets can be tracked flexibly. The estimation performance of traditional matched filter-based methods would deteriorate dramatically for multiple targets tracking, since the weak target is masked by the strong target or the strong sidelobes. In order to solve the problems mentioned above, this paper aims at developing a joint range-Doppler-angle estimation solution for an intelligent tracking system with a commercial frequency modulation radio station (noncooperative illuminator of opportunity) and a uniform linear array. First, a gridless sparse method is proposed for simultaneous angle-range-Doppler estimation with atomic norm minimization. Based on the integrated computing, multiple workstations or servers of the data process center in the intelligent tracking system can cooperate with each other to accelerate the data process. Then a suboptimal method, which estimates three parameters in a sequential way, is proposed based on grid sparse method. The range-Doppler of each target is iteratively estimated by exploiting the joint sparsity in multiple surveillance antennas. A simple beamforming method is used to estimate the angles in turn by exploiting the angle information in the joint sparse coefficients. Simulation result and real test show that the proposed solution can effectively detect weak targets in an iterative manner.</td>
</tr>
<tr><td>Social Big-Data-Based Content Dissemination in Internet of Vehicles</td>
<td align="right">2018</td>
<td>By analogy with Internet of things, Internet of vehicles (IoV) that enables ubiquitous information exchange and content sharing among vehicles with little or no human intervention is a key enabler for the intelligent transportation industry. In this paper, we study how to combine both the physical and social layer information for realizing rapid content dissemination in device-to-device vehicle-to-vehicle (D2D-V2V)-based IoV networks. In the physical layer, headway distance of vehicles is modeled as a Wiener process, and the connection probability of D2D-V2V links is estimated by employing the Kolmogorov equation. In the social layer, the social relationship tightness that represents content selection similarities is obtained by Bayesian nonparametric learning based on real-world social big data, which are collected from the largest Chinese microblogging service Sina Weibo and the largest Chinese video-sharing site Youku. Then, a price-rising-based iterative matching algorithm is proposed to solve the formulated joint peer discovery, power control, and channel selection problem under various quality-of-service requirements. Finally, numerical results demonstrate the effectiveness and superiority of the proposed algorithm from the perspectives of weighted sum rate and matching satisfaction gains.</td>
</tr>
<tr><td>Millimeter-Wave Wireless Communications for IoT-Cloud Supported Autonomous Vehicles: Overview, Design, and Challenges</td>
<td align="right">2017</td>
<td>Autonomous vehicles are a rising technology in the near future to provide a safe and efficient transportation experience. Vehicular communication systems are indispensable components in autonomous vehicles to share road conditions in a wireless manner. With the exponential increase of traffic data, conventional wireless technologies preliminarily show their incompetence because of limited bandwidth. This article explores the capability of millimeter-wave communications for autonomous vehicles. As the next-generation wireless technology, mmWave is advanced in its multi-gigabit transmittability and beamforming technique. Based on these features, we propose the novel design of a vehicular mmWave system combining the advantages of the Internet of Things and cloud computing. This mmWave system supports vehicles sharing multi-gigabit data about the surrounding environment and recognizing objects via the cloud in real time. Therefore, autonomous vehicles are able to determine the optimal driving strategy instantaneously.</td>
</tr>
<tr><td>Joint Offloading and Computing Optimization in Wireless Powered Mobile-Edge Computing Systems</td>
<td align="right">2018</td>
<td>Mobile-edge computing (MEC) and wireless power transfer (WPT) have been recognized as promising techniques in the Internet of Things era to provide massive low-power wireless devices with enhanced computation capability and sustainable energy supply. In this paper, we propose a unified MEC-WPT design by considering a wireless powered multiuser MEC system, where a multiantenna access point (AP) (integrated with an MEC server) broadcasts wireless power to charge multiple users and each user node relies on the harvested energy to execute computation tasks. With MEC, these users can execute their respective tasks locally by themselves or offload all or part of them to the AP based on a time-division multiple access protocol. Building on the proposed model, we develop an innovative framework to improve the MEC performance, by jointly optimizing the energy transmit beamforming at the AP, the central processing unit frequencies and the numbers of offloaded bits at the users, as well as the time allocation among users. Under this framework, we address a practical scenario where latency-limited computation is required. In this case, we develop an optimal resource allocation scheme that minimizes the AP&#39;s total energy consumption subject to the users&#39; individual computation latency constraints. Leveraging the state-of-the-art optimization techniques, we derive the optimal solution in a semiclosed form. Numerical results demonstrate the merits of the proposed design over alternative benchmark schemes.</td>
</tr>
<tr><td>Enhanced Fingerprinting and Trajectory Prediction for IoT Localization in Smart Buildings</td>
<td align="right">2016</td>
<td>Location service is one of the primary services in smart automated systems of Internet of Things (IoT). For various location-based services, accurate localization has become a key issue. Recently, research on IoT localization systems for smart buildings has been attracting increasing attention. In this paper, we propose a novel localization approach that utilizes the neighbor relative received signal strength to build the fingerprint database and adopts a Markov-chain prediction model to assist positioning. The approach is called the novel localization method (LNM) in short. In the proposed LNM scheme, the history data of the pedestrian&#39;s locations are analyzed to further lower the unpredictable signal fluctuations in a smart building environment, meanwhile enabling calibration-free positioning for various devices. The performance evaluation conducted in a realistic environment shows that the presented method demonstrates superior localization performance compared with well-known existing schemes, especially when the problems of device heterogeneity and WiFi signals fluctuation exist.</td>
</tr>
<tr><td>Applicability of Big Data Techniques to Smart Cities Deployments</td>
<td align="right">2017</td>
<td>This paper presents the main foundations of big data applied to smart cities. A general Internet of Things based architecture is proposed to be applied to different smart cities applications. We describe two scenarios of big data analysis. One of them illustrates some services implemented in the smart campus of the University of Murcia. The second one is focused on a tram service scenario, where thousands of transit-card transactions should be processed. Results obtained from both scenarios show the potential of the applicability of this kind of techniques to provide profitable services of smart cities, such as the management of the energy consumption and comfort in smart buildings, and the detection of travel profiles in smart transport.</td>
</tr>
<tr><td>Cloud-Assisted IoT-Based SCADA Systems Security: A Review of the State of the Art and Future Challenges</td>
<td align="right">2016</td>
<td>Industrial systems always prefer to reduce their operational expenses. To support such reductions, they need solutions that are capable of providing stability, fault tolerance, and flexibility. One such solution for industrial systems is cyber physical system (CPS) integration with the Internet of Things (IoT) utilizing cloud computing services. These CPSs can be considered as smart industrial systems, with their most prevalent applications in smart transportation, smart grids, smart medical and eHealthcare systems, and many more. These industrial CPSs mostly utilize supervisory control and data acquisition (SCADA) systems to control and monitor their critical infrastructure (CI). For example, WebSCADA is an application used for smart medical technologies, making improved patient monitoring and more timely decisions possible. The focus of the study presented in this paper is to highlight the security challenges that the industrial SCADA systems face in an IoT-cloud environment. Classical SCADA systems are already lacking in proper security measures; however, with the integration of complex new architectures for the future Internet based on the concepts of IoT, cloud computing, mobile wireless sensor networks, and so on, there are large issues at stakes in the security and deployment of these classical systems. Therefore, the integration of these future Internet concepts needs more research effort. This paper, along with highlighting the security challenges of these CI&#39;s, also provides the existing best practices and recommendations for improving and maintaining security. Finally, this paper briefly describes future research directions to secure these critical CPSs and help the research community in identifying the research gaps in this regard.</td>
</tr>
<tr><td>A Novel Grading Biomarker for the Prediction of Conversion From Mild Cognitive Impairment to Alzheimer&#39;s Disease</td>
<td align="right">2017</td>
<td>Objective: Identifying mild cognitive impairment (MCI) subjects who will progress to Alzheimer&#39;s disease (AD) is not only crucial in clinical practice, but also has a significant potential to enrich clinical trials. The purpose of this study is to develop an effective biomarker for an accurate prediction of MCI-to-AD conversion from magnetic resonance images. Methods: We propose a novel grading biomarker for the prediction of MCI-to-AD conversion. First, we comprehensively study the effects of several important factors on the performance in the prediction task including registration accuracy, age correction, feature selection, and the selection of training data. Based on the studies of these factors, a grading biomarker is then calculated for each MCI subject using sparse representation techniques. Finally, the grading biomarker is combined with age and cognitive measures to provide a more accurate prediction of MCI-to-AD conversion. Results: Using the Alzheimer&#39;s Disease Neuroimaging Initiative (ADNI) dataset, the proposed global grading biomarker achieved an area under the receiver operating characteristic curve (AUC) in the range of 79-81% for the prediction of MCI-to-AD conversion within three years in tenfold cross validations. The classification AUC further increases to 84-92% when age and cognitive measures are combined with the proposed grading biomarker. Conclusion: The obtained accuracy of the proposed biomarker benefits from the contributions of different factors: a tradeoff registration level to align images to the template space, the removal of the normal aging effect, selection of discriminative voxels, the calculation of the grading biomarker using AD and normal control groups, and the integration of sparse representation technique and the combination of cognitive measures. Significance: The evaluation on the ADNI dataset shows the efficacy of the proposed biomarker and demonstrates a significant contribution in accurate prediction of MCI-to-AD conversion.</td>
</tr>
<tr><td>A Software Architecture Enabling the Web of Things</td>
<td align="right">2015</td>
<td>The Internet of Things (IoT) will include billions of smart “things” connected to the Web and characterized by sensing, actuating, and data processing capabilities. In this context, also known as Web of Things (WoT), the user should ideally be able to collect information provided by smart things, and to mash-up them to obtain value-added services. However, in the current solutions, the access to physical objects is poorly scalable and efficient, the communications are often unidirectional (from the devices to the users), and only tech-savvy people are able to develop mash-up applications. Based on these assumptions, we propose a software architecture to easily mash-up constrained application protocol (CoAP) resources. It is able to discover the available devices and to virtualize them outside the physical network. These virtualizations are then exposed to the upper layers by a REpresentational State Transfer (REST) interface, so that the physical devices interact only with their own virtualization. Furthermore, the system provides simplified tools allowing the development of mash-up applications to different-skilled users. Finally, the architecture allows not only to monitor but also to control the devices, thus establishing a bidirectional communication channel. To evaluate the proposal, we deeply modify and integrate some existing software components to realize an instance of the architecture.</td>
</tr>
<tr><td>The CTTC 5G End-to-End Experimental Platform : Integrating Heterogeneous Wireless/Optical Networks, Distributed Cloud, and IoT Devices</td>
<td align="right">2016</td>
<td>The Internet of Things (IoT) will facilitate a wide variety of applications in different domains, such as smart cities, smart grids, industrial automation (Industry 4.0), smart driving, assistance of the elderly, and home automation. Billions of heterogeneous smart devices with different application requirements will be connected to the networks and will generate huge aggregated volumes of data that will be processed in distributed cloud infrastructures. On the other hand, there is also a general trend to deploy functions as software (SW) instances in cloud infrastructures [e.g., network function virtualization (NFV) or mobile edge computing (MEC)]. Thus, the next generation of mobile networks, the fifth-generation (5G), will need not only to develop new radio interfaces or waveforms to cope with the expected traffic growth but also to integrate heterogeneous networks from end to end (E2E) with distributed cloud resources to deliver E2E IoT and mobile services. This article presents the E2E 5G platform that is being developed by the Centre Tecnol?gic de Telecomunicacions de Catalunya (CTTC), the first known platform capable of reproducing such an ambitious scenario.</td>
</tr>
<tr><td>Software defined healthcare networks</td>
<td align="right">2015</td>
<td>With the increasingly serious problem of the aging population, creating an efficient and real-time health management and feedback system based on the healthcare Internet of Things (HealthIoT) is an urgent need. Specifically, wearable technology and robotics can enable a user to collect the required human signals in a comfortable way. HealthIoT is the basic infrastructure for realizing health surveillance, and should be flexible to support multiple application demands and facilitate the management of infrastructure. Therefore, enlightened by the software defined network, we put forward a smart healthcare oriented control method to software define health monitoring in order to make the network more elastic. In this article, we design a centralized controller to manage physical devices and provide an interface for data collection, transmission, and processing to develop a more flexible health surveillance application that is full of personalization. With these distinguished characteristics, various applications can coexist in the shared infrastructure, and each application can demand that the controller customize its own data collection, transmission, and processing as required, and pass the specific configuration of the physical device. This article discusses the background, advantages, and design details of the architecture proposed, which is achieved by an open-ended question and a potential solution. It opens a new research direction of HealthIoT and smart homes.</td>
</tr>
<tr><td>NextMe: Localization Using Cellular Traces in Internet of Things</td>
<td align="right">2015</td>
<td>The Internet of Things (IoT) opens up tremendous opportunities to location-based industrial applications that leverage both Internet-resident resources and phones&#39; processing power and sensors to provide location information. Location-based service is one of the vital applications in commercial, economic, and public domains. In this paper, we propose a novel localization scheme called NextMe, which is based on cellular phone traces. We find that the mobile call patterns are strongly correlated with the co-locate patterns. We extract such correlation as social interplay from cellular calls, and use it for location prediction from temporal and spatial perspectives. NextMe consists of data preprocessing, call pattern recognition, and a hybrid predictor. To design the call pattern recognition module, we introduce the notions of critical calls and corresponding patterns. In addition, NextMe does not require that the cell tower addresses should be bounded with concrete coordinates, e.g., global positioning system (GPS) coordinates. We validate NextMe across MIT Reality Mining Dataset, involving 500 000 h of continuous behavior information and 112 508 cellular calls. Experimental results show that NextMe achieves fine-grained prediction accuracy at cell tower level in the forthcoming 1-6 h with 12% accuracy enhancement averagely from cellular calls.</td>
</tr>
<tr><td>Scalable Energy-Efficient Distributed Data Analytics for Crowdsensing Applications in Mobile Environments</td>
<td align="right">2015</td>
<td>We are witnessing a new revolution in computing and communication involving symbiotic networks of people (social networks), intelligent devices, smart mobile computing, and communication devices that will form cyber-physical social systems. The emergence of intelligent devices with monitoring, sensing, and actuation capabilities referred to as Internet of Things and social networks have increased the popularity of novel social applications such as crowdsourcing and crowdsensing. The upsurge of such applications has fostered the need for scalable cost-efficient platforms that can enable distributed data analytics. In this paper, we propose CARDAP, a scalable, energy-efficient, generic and extensible component-based distributed data analytics platform for mobile crowdsensing (MCS) applications. CARDAP incorporates on-the-move activity recognition and a number of energy efficient data delivery strategies using real-time mobile data stream mining. We propose and develop theoretical cost models for typical crowdsensing application scenarios. Experimental evaluations of CARDAP using a proof-of-concept MCS scenario validate the theoretical cost model estimates and demonstrate the platform&#39;s ability to deliver significant benefits in energy, resource, and query processing efficiency.</td>
</tr>
<tr><td>An Efficient Anonymous Batch Authentication Scheme Based on HMAC for VANETs</td>
<td align="right">2016</td>
<td>In vehicular ad hoc networks (VANETs), when a vehicle receives a message, the certificate revocation list (CRL) checking process will operate before certificate and signature verification. However, large communication sources, storage space, and checking time are needed for CRLs that cause the privacy disclosure issue as well. To address these issues, in this paper, we propose an efficient anonymous batch authentication scheme (ABAH) to replace the CRL checking process by calculating the hash message authentication code (HMAC). In our scheme, we first divide the precinct into several domains, in which road-side units (RSUs) manage vehicles in a localized manner. Then, we adopt pseudonyms to achieve privacy-preserving and realize batch authentication by using an identity-based signature (IBS). Finally, we use HMAC to avoid the time-consuming CRL checking and to ensure the integrity of messages that may get loss in previous batch authentication. The security and performance analysis are carried out to demonstrate that ABAH is more efficient in terms of verification delay than the conventional authentication methods employing CRLs. Meanwhile, our solution can keep conditional privacy in VANETs.</td>
</tr>
<tr><td>Internet of Things and Big Data Analytics for Smart and Connected Communities</td>
<td align="right">2016</td>
<td>This paper promotes the concept of smart and connected communities SCC, which is evolving from the concept of smart cities. SCC are envisioned to address synergistically the needs of remembering the past (preservation and revitalization), the needs of living in the present (livability), and the needs of planning for the future (attainability). Therefore, the vision of SCC is to improve livability, preservation, revitalization, and attainability of a community. The goal of building SCC for a community is to live in the present, plan for the future, and remember the past. We argue that Internet of Things (IoT) has the potential to provide a ubiquitous network of connected devices and smart sensors for SCC, and big data analytics has the potential to enable the move from IoT to real-time control desired for SCC. We highlight mobile crowdsensing and cyber-physical cloud computing as two most important IoT technologies in promoting SCC. As a case study, we present TreSight, which integrates IoT and big data analytics for smart tourism and sustainable cultural heritage in the city of Trento, Italy.</td>
</tr>
<tr><td>Perspectives on Energy Storage for Flexible Electronic Systems</td>
<td align="right">2015</td>
<td>If truly thin embedded and human worn flexible electronics are to become a commercial reality for wearable electronics, medical devices, and internet of things tags, effective energy storage technologies that safely and robustly match the mechanical flexibility of the overall system form factor are required. At the same time, the energy and transient power needs of functions such as wireless connectivity, information display, and high sample rate sensing must be supported. These capabilities have time-dependent power and current requirements often not captured in simple energy and capacity metrics. In this paper, a progression of energy storage approaches, challenges and learning experiences will be presented from the perspective of an energy storage technology developer. The essential requirements for energy storage for feature-driven applications in flexible electronics are addressed with the goal of finding the most compelling fit between products needs, consumer safety and the technology capabilities of different energy storage approaches. Micropower modules from supercapacitors to microbatteries and their limitations for flexible electronics will be discussed in terms of capacity, power and charge retention as the starting point. Following this discussion, limitations of lithium technologies in this flexible and thin (&amp;lt;; 1 mm) application space are also outlined. This paper then presents a review of key requirements for energy storage for high functionality flexible electronics prototype systems and some approaches that have been explored to meet those needs. This leads to the conclusion that safe, low cost, flexible electronics energy storage requirements may be most appropriately met using intrinsically stable battery chemistry. Furthermore, such a materials approach allows for simpler lower cost processing and packaging, such as additive printing and roll to roll processing of thin and therefore more mechanically flexible cells. Examples and performance data from such a zinc polymer battery technology are given and compared to other thin and flexible battery approaches.</td>
</tr>
<tr><td>An Energy-Efficient and Delay-Aware Wireless Computing System for Industrial Wireless Sensor Networks</td>
<td align="right">2015</td>
<td>Industrial wireless sensor networks have attracted much attention as a cornerstone to making the smart factories real. Utilizing industrial wireless sensor networks as a base for smart factories makes it possible to optimize the production line without human resources, since it provides industrial Internet of Things service, where various types of data are collected from sensors and mined to control the machines based on the analysis result. On the other hand, a fog computing node, which executes such real-time feedback control, should be capable of real-time data collection, management, and processing. To achieve these requirements, in this paper, we introduce wireless computing system (WCS) as a fog computing node. Since there are a lot of servers and each server has 60 GHz antennas to connect to other servers and sensors, WCS has high collecting and processing capabilities. However, in order to fulfill a demand for real-time feedback control, WCS needs to satisfy an acceptable delay for data collection. In addition, lower power consumption is required in order to reduce the cost for the factory operation. Therefore, we propose an energy-efficient and delay-aware WCS. Since there is a tradeoff relationship between the power consumption and the delay for data collection, our proposed system controls the sleep schedule and the number of links to minimize the power consumption while satisfying an acceptable delay constraint. Furthermore, the effectiveness of our proposed system is evaluated through extensive computer simulations.</td>
</tr>
<tr><td>GreenNet: An Energy-Harvesting IP-Enabled Wireless Sensor Network</td>
<td align="right">2015</td>
<td>This paper presents GreenNet, an energy efficient and fully operational protocol stack for IP-enabled wireless sensor networks based on the IEEE 802.15.4 beacon-enabled mode. The stack runs on a hardware platform with photovoltaic cell energy harvesting developed by STMicroelectronics (STM) that can operate autonomously for long periods of time. GreenNet integrates several standard mechanisms and enhances existing protocols, which results in an operational platform with the performance beyond the current state of the art. In particular, it includes the IEEE 802.15.4 beacon-enabled medium access control (MAC) integrated with lightweight IP routing for achieving very low duty cycles. It offers an advanced discovery scheme that accelerates the process of joining the network and proposes an adaptation scheme for adjusting the duty cycle of harvested nodes to the available energy for increased performance. Finally, it supports security at two levels: a basic standard secure operation at the link layer and advanced scalable data payload security. This paper describes all techniques and mechanisms for saving energy and operating at very low duty cycles. It also provides an evaluation of the performance and energy consumption of GreenNet.</td>
</tr>
<tr><td>A 6.45&lt;formula formulatype=&quot;inline&quot;&gt;&lt;tex Notation=&quot;TeX&quot;&gt;$\mu{\rm W}$&lt;/tex&gt;&lt;/formula&gt;Self-Powered SoC With Integrated Energy-Harvesting Power Management and ULP Asymmetric Radios for Portable Biomedical Systems</td>
<td align="right">2015</td>
<td>This paper presents a batteryless system-on-chip (SoC) that operates off energy harvested from indoor solar cells and/or thermoelectric generators (TEGs) on the body. Fabricated in a commercial 0.13 μW process, this SoC sensing platform consists of an integrated energy harvesting and power management unit (EH-PMU) with maximum power point tracking, multiple sensing modalities, programmable core and a low power microcontroller with several hardware accelerators to enable energy-efficient digital signal processing, ultra-low-power (ULP) asymmetric radios for wireless transmission, and a 100 nW wake-up radio. The EH-PMU achieves a peak end-to-end efficiency of 75% delivering power to a 100 μA load. In an example motion detection application, the SoC reads data from an accelerometer through SPI, processes it, and sends it over the radio. The SPI and digital processing consume only 2.27 μW, while the integrated radio consumes 4.18 μW when transmitting at 187.5 kbps for a total of 6.45 μW.</td>
</tr>
<tr><td>A Privacy-Preserving Message Forwarding Framework for Opportunistic Cloud of Things</td>
<td align="right">2018</td>
<td>As an emerging communication platform, opportunistic Cloud of Things (CoT) is promising for clients to exchange messages through opportunistic contacts in cloud computing-enabled Internet of Things. Recently, numerous socially aware schemes have been put forward, leveraging users’ social attributes and contact history to predict future contacts with the purpose of improving message forwarding efficiency and network throughput. However, individual privacy is generally overlooked in the prediction process and transmission stage of opportunistic CoT. In this paper, we construct a privacy-preserving message forwarding framework for opportunistic CoT to guarantee individual privacy and improve transmission efficiency. We first set up a two-layer architecture of a cloud server to improve communication efficiency for terminal clients. By integrating a security-based mobility prediction algorithm with a routing decision process, our scheme can effectively protect individual privacy. We integrate an attribute-based cryptographic algorithm with a message delivery process to enable our scheme to resist attacks, such as Sybil attack, drop for profit, and data tampered attack. Compared with some existing solutions, our scheme improves network security significantly at the cost of slightly increased communication overhead.</td>
</tr>
<tr><td>Mobile-Edge Computing and the Internet of Things for Consumers: Extending cloud computing and services to the edge of the network</td>
<td align="right">2016</td>
<td>Current activities in the Internet of Things (IoT) are focused on architectures, protocols, and networking for the efficient interconnection of heterogeneous things, infrastructure deployment, and creation of value-added services. The majority of the IoT products, services, and platforms are supported by cloud-computing platforms. With the IoT being a multidisciplinary ecosystem, it is now being utilized in connection with scenarios demanding real-time data processing and feedback, for example, connected and autonomous vehicles scenarios. Cloud platforms are not suitable for scenarios involving real-time operation, low latency requirements, and high quality of service (QoS). Recently, mobile-edge computing (MEC) has gained momentum from the industry to address the mentioned requirements. MEC is a novel paradigm that extends cloud-computing capabilities and services to the edge of the network. Due to dense geographical distribution, proximity to consumers, support for high mobility, and open platform, MEC can support applications and services with reduced latency and improved QoS. Thus, MEC is becoming an important enabler of consumer-centric IoT applications and services that demand real-time operations. The OpenFog Consortium and standards development organizations like ETSI have also recognized the benefits the IoT and MEC can bring to consumers. Potential applications for MEC-enabled IoT include smart mobility, connected vehicles, emergency response, smart cities, content distribution, and location-based services.</td>
</tr>
<tr><td>Attitudes and Perceptions of IoT Security in Critical Societal Services</td>
<td align="right">2016</td>
<td>A quiet revolution that impacts several sectors, ranging over transport, home automation, energy, industrial control, and health services is undergoing with addition of new networked devices leading to enhanced services. In this paper, we aim to identify information security requirements that are common over several (vertical) sectors, and in particular, ones that impact critical societal services, namely, the energy, water, and health management systems. We present the results of an interview-based study where actors in these sectors were asked about their perceptions and attitudes on the security of Internet of Things (IoT). We set these perceptions and attitudes in context through a literature review of IoT security, and relate to current challenges in this area. This paper demonstrates that despite an overall optimistic view on IoT in critical societal services, there is a lack of consensus on risks related to IoT security.</td>
</tr>
<tr><td>Quantifying User Reputation Scores, Data Trustworthiness, and User Incentives in Mobile Crowd-Sensing</td>
<td align="right">2017</td>
<td>Ubiquity of mobile devices with rich sensory capabilities has given rise to the mobile crowd-sensing (MCS) concept, in which a central authority (the platform) and its participants (mobile users) work collaboratively to acquire sensory data over a wide geographic area. Recent research in MCS highlights the following facts: 1) a utility metric can be defined for both the platform and the users, quantifying the value received by either side; 2) incentivizing the users to participate is a non-trivial challenge; 3) correctness and truthfulness of the acquired data must be verified, because the users might provide incorrect or inaccurate data, whether due to malicious intent or malfunctioning devices; and 4) an intricate relationship exists among platform utility, user utility, user reputation, and data trustworthiness, suggesting a co-quantification of these inter-related metrics. In this paper, we study two existing approaches that quantify crowd-sensed data trustworthiness, based on statistical and vote-based user reputation scores. We introduce a new metric - collaborative reputation scores - to expand this definition. Our simulation results show that collaborative reputation scores can provide an effective alternative to the previously proposed metrics and are able to extend crowd sensing to applications that are driven by a centralized as well as decentralized control.</td>
</tr>
<tr><td>A Hybrid Data Compression Scheme for Power Reduction in Wireless Sensors for IoT</td>
<td align="right">2017</td>
<td>This paper presents a novel data compression and transmission scheme for power reduction in Internet-of-Things (IoT) enabled wireless sensors. In the proposed scheme, data is compressed with both lossy and lossless techniques, so as to enable hybrid transmission mode, support adaptive data rate selection and save power in wireless transmission. Applying the method to electrocardiogram (ECG), the data is first compressed using a lossy compression technique with a high compression ratio (CR). The residual error between the original data and the decompressed lossy data is preserved using entropy coding, enabling a lossless restoration of the original data when required. Average CR of 2.1× and 7.8× were achieved for lossless and lossy compression respectively with MIT/BIH database. The power reduction is demonstrated using a Bluetooth transceiver and is found to be reduced to 18% for lossy and 53% for lossless transmission respectively. Options for hybrid transmission mode, adaptive rate selection and system level power reduction make the proposed scheme attractive for IoT wireless sensors in healthcare applications.</td>
</tr>
<tr><td>Wirelessly Powered Backscatter Communication Networks: Modeling, Coverage, and Capacity</td>
<td align="right">2017</td>
<td>Future Internet-of-Things (IoT) will connect billions of small computing devices embedded in the environment and support their device-to-device (D2D) communication. Powering the massive number of embedded devices is a key challenge of designing IoT, since batteries increase the devices&#39; form factors and battery recharging/replacement is difficult. To tackle this challenge, we propose a novel network architecture that enables D2D communication between passive nodes by integrating wireless power transfer and backscatter communication, which is called a wirelessly powered backscatter communication (WP-BackCom) network. In this network, standalone power beacons (PBs) are deployed for wirelessly powering nodes by beaming unmodulated carrier signals to targeted nodes. Provisioned with a backscatter antenna, a node transmits data to an intended receiver by modulating and reflecting a fraction of a carrier signal. Such transmission by backscatter consumes orders-of-magnitude less power than a traditional radio. Thereby, the dense deployment of low-complexity PBs with high transmission power can power a large-scale IoT. In this paper, a WP-BackCom network is modeled as a random Poisson cluster process in the horizontal plane where PBs are Poisson distributed and active ad hoc pairs of backscatter communication nodes with fixed separation distances form random clusters centered at PBs. The backscatter nodes can harvest energy from and backscatter carrier signals transmitted by PBs. Furthermore, the transmission power of each node depends on the distance from the associated PB. Applying stochastic geometry, the network coverage probability and transmission capacity are derived and optimized as functions of backscatter parameters, including backscatter duty cycle, reflection coefficient, and the PB density. The effects of the parameters on network performance are quantified.</td>
</tr>
<tr><td>UAV-Based IoT Platform: A Crowd Surveillance Use Case</td>
<td align="right">2017</td>
<td>Unmanned aerial vehicles are gaining a lot of popularity among an ever growing community of amateurs as well as service providers. Emerging technologies, such as LTE 4G/5G networks and mobile edge computing, will widen the use case scenarios of UAVs. In this article, we discuss the potential of UAVs, equipped with IoT devices, in delivering IoT services from great heights. A high-level view of a UAV-based integrative IoT platform for the delivery of IoT services from large height, along with the overall system orchestrator, is presented in this article. As an envisioned use case of the platform, the article demonstrates how UAVs can be used for crowd surveillance based on face recognition. To evaluate the use case, we study the offloading of video data processing to a MEC node compared to the local processing of video data onboard UAVs. For this, we developed a testbed consisting of a local processing node and one MEC node. To perform face recognition, the Local Binary Pattern Histogram method from the Open Source Computer Vision is used. The obtained results demonstrate the efficiency of the MEC-based offloading approach in saving the scarce energy of UAVs, reducing the processing time of recognition, and promptly detecting suspicious persons.</td>
</tr>
<tr><td>A Secure IoT-Based Healthcare System With Body Sensor Networks</td>
<td align="right">2016</td>
<td>The ever-increasing advancement in communication technologies of modern smart objects brings with it a newera of application development for Internet of Things (IoT)-based networks. In particular, owing to the contactless-ness nature and efficiency of the data retrieval of mobile smart objects, such as wearable equipment or tailored bio-sensors, several innovative types of healthcare systems with body sensor networks (BSN) have been proposed. In this paper, we introduce a secure IoT-based healthcare system, which operates through the BSN architecture. To simultaneously achieve system efficiency and robustness of transmission within public IoT-based communication networks, we utilize robust crypto-primitives to construct two communication mechanisms for ensuring transmission confidentiality and providing entity authentication among smart objects, the local processing unit and the backend BSN server. Moreover, we realize the implementation of the proposed healthcare system with the Raspberry PI platform to demonstrate the practicability and feasibility of the presented mechanisms.</td>
</tr>
<tr><td>Massive MIMO: ten myths and one critical question</td>
<td align="right">2016</td>
<td>Wireless communications is one of the most successful technologies in modern years, given that an exponential growth rate in wireless traffic has been sustained for over a century (known as Cooper&#39;s law). This trend will certainly continue, driven by new innovative applications; for example, augmented reality and the Internet of Things. Massive MIMO has been identified as a key technology to handle orders of magnitude more data traffic. Despite the attention it is receiving from the communication community, we have personally witnessed that Massive MIMO is subject to several widespread misunderstandings, as epitomized by following (fictional) abstract: “The Massive MIMO technology uses a nearly infinite number of high-quality antennas at the base stations. By having at least an order of magnitude more antennas than active terminals, one can exploit asymptotic behaviors that some special kinds of wireless channels have. This technology looks great at first sight, but unfortunately the signal processing complexity is off the charts and the antenna arrays would be so huge that it can only be implemented in millimeter-wave bands.” These statements are, in fact, completely false. In this overview article, we identify 10 myths and explain why they are not true. We also ask a question that is critical for the practical adoption of the technology and which will require intense future research activities to answer properly. We provide references to key technical papers that support our claims, while a further list of related overview and technical papers can be found at the Massive MIMO Info Point: http://massivemimo. eu.</td>
</tr>
<tr><td>Cloud robotics: Current status and open issues</td>
<td align="right">2016</td>
<td>With the development of cloud computing, big data, and other emerging technologies, the integration of cloud technology and multi-robot systems makes it possible to design multi-robot systems with improved energy efficiency, high real-time performance, and low cost. In order to address the potential of clouds in enhancing robotics for industrial systems, this paper describes the basic concepts and development process of cloud robotics and the overall architecture of these systems. Then, the major driving forces behind the development of cloud robotics are carefully analyzed from the point of view of cloud computing, big data, open source resources, robot cooperative learning, and network connectivity. Subsequently, the key issues and challenges in the current cloud robotic systems are proposed, and some possible solutions are also given. Finally, the potential value of cloud robotic systems in different practical applications is discussed.</td>
</tr>
<tr><td>Threats to Networking Cloud and Edge Datacenters in the Internet of Things</td>
<td align="right">2016</td>
<td>Several application domains are collecting data using Internet of Things sensing devices and shipping it to remote cloud datacenters for analysis (fusion, storage, and processing). Data analytics activities raise a new set of technical challenges from the perspective of ensuring end-to-end security and privacy of data as it travels from an edge datacenter (EDC) to a cloud datacenter (CDC) (or vice versa). This article discusses the security threats in EDCs and CDCs by dividing the complete network structure into three layers: perception layer, network layer, and application layer.</td>
</tr>
<tr><td>Technologies for 5G Networks: Challenges and Opportunities</td>
<td align="right">2017</td>
<td>Mobile data traffic has grown substantially owing to the widespread use of data-hungry devices such as smart handsets and laptops. This has encouraged researchers and system designers to develop more efficient network designs. The authors review the technologies that can support speeds of multiple Gbps for future fifth-generation (5G) networks. They examine the many challenges, problems, and questions that arise in the research and design stage, and conclude that the anticipated high-traffic demands and low-latency requirements stemming from the Internet of Things (IoT) and machine-to-machine (M2M) communications can be met only with radical changes to the network paradigm. These include harnessing the millimeter-wave band for the dense deployment of small cells. Future wireless systems will include myriad smart features and applications to make 5G the most intelligent and dominant wireless technology thus far.</td>
</tr>
<tr><td>Evaluation of the IoT LoRaWAN Solution for Distributed Measurement Applications</td>
<td align="right">2017</td>
<td>Internet of Things (IoT) is based on data collection, where billions of sensors sample the real world; in other words, the IoT includes a giant distributed measurement system (DMS). A question still requiring an answer is: Are the IoT technologies usable to enhance traditional measurement systems, since they have been developed for a very similar objective? In this paper, the use of a long-range (LoRa) technology, originally developed for IoT, is investigated with the aim of implementing DMSs. After the conclusion that LoRa and LoRa wide area network architectures show a good match with measurement systems, this paper focuses on the characterization of time-related performance indicators that are important for distributed systems. The experimental results show the capability of low-cost transceiver to schedule the transmission of frames with a standard uncertainty less than 3 μs; and an acceptable longterm clock stability (Allan Deviation) of commercial available devices (nodes and packet forwarders) for application such as smart metering, smart building, and process industry.</td>
</tr>
<tr><td>FogRoute: DTN-Based Data Dissemination Model in Fog Computing</td>
<td align="right">2017</td>
<td>Fog computing, known as “cloud closed to ground,” deploys light-weight compute facility, called Fog servers, at the proximity of mobile users. By precatching contents in the Fog servers, an important application of Fog computing is to provide high-quality low-cost data distributions to proximity mobile users, e.g., video/live streaming and ads dissemination, using the single-hop low-latency wireless links. A Fog computing system is of a three tier Mobile-Fog-Cloud structure; mobile user gets service from Fog servers using local wireless connections, and Fog servers update their contents from Cloud using the cellular or wired networks. This, however, may incur high content update cost when the bandwidth between the Fog and Cloud servers is expensive, e.g., using the cellular network, and is therefore inefficient for nonurgent, high volume contents. How to economically utilize the Fog-Cloud bandwidth with guaranteed download performance of users thus represents a fundamental issue in Fog computing. In this paper, we address the issue by proposing a hybrid data dissemination framework which applies software-defined network and delay-tolerable network (DTN) approaches in Fog computing. Specifically, we decompose the Fog computing network with two planes, where the cloud is a control plane to process content update queries and organize data flows, and the geometrically distributed Fog servers form a data plane to disseminate data among Fog servers with a DTN technique. Using extensive simulations, we show that the proposed framework is efficient in terms of data-dissemination success ratio and content convergence time among Fog servers.</td>
</tr>
<tr><td>Software-defined internet of things for smart urban sensing</td>
<td align="right">2015</td>
<td>With more people living in cities, urban sensing is urgently required to create a comfortable and convenient living environment. As Internet of Things (IoT) is the fundamental infrastructure to realize urban sensing, it should be flexible to support various application requirements and convenient management of infrastructure. Inspired by software-defined networking, which aims to make networks more flexible, the authors propose a software-defined IoT architecture for smart urban sensing. This architecture decouples urban sensing applications from the physical infrastructure. Centralized controllers are designed to manage physical devices and provide APIs of data acquisition, transmission, and processing services to develop urban sensing applications. With these properties, various applications can coexist on the shared infrastructure, and each application can request controllers to customize its data acquisition, transmission, and processing on-demand by generating specific configurations of physical devices. This article discusses the background, benefits, and design details of the proposed architecture as well as open problems and potential solutions to realize it, which opens a new research direction for IoT and urban sensing.</td>
</tr>
<tr><td>Standard-based IoT platforms interworking: implementation, experiences, and lessons learned</td>
<td align="right">2016</td>
<td>The Internet-of-Things (IoT) provides a great opportunity to many vertical industries because IoT interconnects various devices such as sensors and actuators and collects/processes data from them in order to improve services and reduce costs. As there exists many IoT technologies in the market, global standards and interworking mechanisms are critical to the success of the IoT. This article introduces standardized interworking interfaces and procedures based on oneM2M global standards, and tests them through use cases involving multiple IoT service platforms. The interworking involves smart city applications/services running on multiple IoT service layer platforms interoperating with each other. The main purpose of the interworking experiment is to show how machine-to-machine (M2M)/IoT service providers are using oneM2M compliant service layer platforms to deliver services more efficiently across multiple technology domains such as smart city. Because the deployment configurations of this interworking experiment span multiple domains, and the IoT devices and platforms are from different companies, we believe that this interworking experiment clearly proves that global IoT standards specifications can foster implementations of a service layer that enables services and interoperability between devices/device networks and cloud-based applications.</td>
</tr>
<tr><td>Security and Privacy for Cloud-Based IoT: Challenges</td>
<td align="right">2017</td>
<td>The Internet of Things is increasingly becoming a ubiquitous computing service, requiring huge volumes of data storage and processing. Unfortunately, due to the unique characteristics of resource constraints, self-organization, and shortrange communication in IoT, it always resorts to the cloud for outsourced storage and computation, which has brought about a series of new challenging security and privacy threats. In this article, we introduce the architecture and unique security and privacy requirements for the next generation mobile technologies on cloud-based IoT, identify the inappropriateness of most existing work, and address the challenging issues of secure packet forwarding and efficient privacy preserving authentication by proposing new efficient privacy preserving data aggregation without public key homomorphic encryption. Finally, several interesting open problems are suggested with promising ideas to trigger more research efforts in this emerging area.</td>
</tr>
<tr><td>IoT-Based Big Data Storage Systems in Cloud Computing: Perspectives and Challenges</td>
<td align="right">2017</td>
<td>Internet of Things (IoT) related applications have emerged as an important field for both engineers and researchers, reflecting the magnitude and impact of data-related problems to be solved in contemporary business organizations especially in cloud computing. This paper first provides a functional framework that identifies the acquisition, management, processing and mining areas of IoT big data, and several associated technical modules are defined and described in terms of their key characteristics and capabilities. Then current research in IoT application is analyzed, moreover, the challenges and opportunities associated with IoT big data research are identified. We also report a study of critical IoT application publications and research topics based on related academic and industry publications. Finally, some open issues and some typical examples are given under the proposed IoT-related research framework.</td>
</tr>
<tr><td>A Cloud to the Ground: The New Frontier of Intelligent and Autonomous Networks of Things</td>
<td align="right">2016</td>
<td>The Internet of Things paradigm is supporting - and will support - an ever increasing number of services and applications impacting on almost every aspect of our everyday life. The current trend is forecasting IoT to connect tens of billions of objects by 2020 yielding a very high volume of data to be acquired, transmitted, and processed. IoT typically relies on cloud computing to process, analyze, and store the data acquired by IoT entities. Unfortunately, the need to transmit all data from the information producing objects to the cloud for a subsequent processing/analysis phase would require a large bandwidth and increase the latency in the decision making process whenever decisions/reactions must be promptly made by the IoT units. The fog computing paradigm aims to address these problems by extending cloud computing toward the edge of the network. In this direction, this article introduces a novel FC-IoT paradigm designed to move computing, storage, and applications/services close to IoT objects so as to reduce communication bandwidth and energy consumption as well as decision making latency. The proposed IoT-based solution has been designed to have intelligent and autonomous IoT objects that are integrated with an FC and fog networking approach. The distinguishing features of the intelligent FC-IoT platform are low latency, self-adaptation, low energy consumption, and spectrum efficiency.</td>
</tr>
<tr><td>A Data Exfiltration and Remote Exploitation Attack on Consumer 3D Printers</td>
<td align="right">2016</td>
<td>With the increased popularity of 3D printers in homes, and industry sectors, such as biomedical and manufacturing, the potential for cybersecurity risks must be carefully considered. Risks may arise from factors such as printer manufacturers not having the requisite levels of security awareness, and not fully understanding the need for security measures to protect intellectual property, and other sensitive data that are stored, accessed, and transmitted from such devices. This paper examines the security features of two different models of MakerBot Industries&#39; consumer-oriented 3D printers and proposes an attack technique that is able to, not only, exfiltrate sensitive data, but also allow for remote manipulation of these devices. The attack steps are discretely modeled using a threat model to enable formal representation of the attack. Specifically, we found that the printers stored the previously printed and currently printing objects on an unauthenticated web server. We also ascertain that the transport layer security implementation on these devices was flawed, which severely affected the security of these devices and allowed for remote exploitation. Countermeasures to the attack that are implementable by both the manufacturer and the user of the printer are presented.</td>
</tr>
<tr><td>CrowdSenSim: a Simulation Platform for Mobile Crowdsensing in Realistic Urban Environments</td>
<td align="right">2017</td>
<td>Smart cities take advantage of recent Information and Communication Technology (ICT) developments to provide added value to existing public services and improve quality of life for the citizens. The Internet of Things (IoT) paradigm makes the Internet more pervasive where objects equipped with computing, storage, and sensing capabilities are interconnected with communication technologies. Because of the widespread diffusion of IoT devices, applying the IoT paradigm to smart cities is an excellent solution to build sustainable ICT platforms. Having citizens involved in the process through mobile crowdsensing (MCS) techniques augments capabilities of these ICT platforms without additional costs. For proper operation, MCS systems require the contribution from a large number of participants. Simulations are therefore a candidate tool to assess the performance of MCS systems. In this paper, we illustrate the design of CrowdSenSim, a simulator for mobile crowdsensing. CrowdSenSim is designed specifically for realistic urban environments and smart cities services. We demonstrate the effectiveness of CrowdSenSim for the most popular MCS sensing paradigms (participatory and opportunistic), and we present its applicability using a smart public street lighting scenario.</td>
</tr>
<tr><td>Quantized Distributed Reception for MIMO Wireless Systems Using Spatial Multiplexing</td>
<td align="right">2015</td>
<td>We study a quantized distributed reception scenario in which a transmitter equipped with multiple antennas sends multiple streams via spatial multiplexing to a large number of geographically separated single antenna receive nodes. This approach is applicable to scenarios such as those enabled by the Internet of Things (IoT) which holds much commercial potential and could facilitate distributed multiple-input multiple-output (MIMO) communication in future systems. The receive nodes quantize their received signals and forward the quantized received signals to a receive fusion center. With global channel knowledge and forwarded quantized information from the receive nodes, the fusion center attempts to decode the transmitted symbols. We assume the transmit vector consists of arbitrary constellation points, and each receive node quantizes its received signal with one bit for each of the real and imaginary parts of the signal to minimize the transmission overhead between the receive nodes and the fusion center. Fusing this data is a nontrivial problem because the receive nodes cannot decode the transmitted symbols before quantization. We develop an optimal maximum likelihood (ML) receiver and a low-complexity zero-forcing (ZF)-type receiver at the fusion center. Despite its suboptimality, the ZF-type receiver is simple to implement and shows comparable performance with the ML receiver in the low signal-to-noise ratio (SNR) regime but experiences an error rate floor at high SNR. It is shown that this error floor can be overcome by increasing the number of receive nodes.</td>
</tr>
<tr><td>Toward Automatic Activity Classification and Movement Assessment During a Sports Training Session</td>
<td align="right">2015</td>
<td>Motion analysis technologies have been widely used to monitor the potential for injury and enhance athlete performance. However, most of these technologies are expensive, can only be used in laboratory environments, and examine only a few trials of each movement action. In this paper, we present a novel ambulatory motion analysis framework using wearable inertial sensors to accurately assess all of an athlete&#39;s activities in real training environment. We first present a system that automatically classifies a large range of training activities using the discrete wavelet transform (DWT) in conjunction with a random forest classifier. The classifier is capable of successfully classifying various activities with up to 98% accuracy. Second, a computationally efficient gradient descent algorithm is used to estimate the relative orientations of the wearable inertial sensors mounted on the shank, thigh, and pelvis of a subject, from which the flexion-extension knee and hip angles are calculated. These angles, along with sacrum impact accelerations, are automatically extracted for each stride during jogging. Finally, normative data are generated and used to determine if a subject&#39;s movement technique differed to the normative data in order to identify potential injury-related factors. For the joint angle data, this is achieved using a curve-shift registration technique. It is envisaged that the proposed framework could be utilized for accurate and automatic sports activity classification and reliable movement technique evaluation in various unconstrained environments for both injury management and performance enhancement.</td>
</tr>
<tr><td>Improved Rule Installation for Real-Time Query Service in Software-Defined Internet of Vehicles</td>
<td align="right">2017</td>
<td>Internet of Vehicles (IoV) has gained considerable attention from industry and academia due to the development of communication technology and smart city. However, a proprietary and closed way of operating hardware in network equipment slows down the progress of new service deployment and extension in IoV. Moreover, the tightly coupled control and data planes in traditional networks significantly increase the complexity and cost of network management. By proposing a novel architecture, i.e., software-defined IoV (SDIV), we adopt a software-defined network (SDN) architecture to address these problems by leveraging its separation of the control plane from the data one and a uniform way to configure heterogeneous switches. However, IoV characteristics introduce some great challenges in rule installation due to the limited size of flow tables at OpenFlow-enabled switches that are the main SDN component. It is necessary to build compact flow tables for IoV scalability. Accordingly, we develop a novel rule installation mechanism to reduce the number of rules for real-time query services in SDIV. We separate the wired data plane from the wireless one and use multicast addresses in the latter. We introduce a destination-driven model in the wired data plane to reduce the number of rules at switches. Experiments with a real data trace show that the developed approach significantly reduces the number of rules without degrading the performance of data transmissions for real-time query services in IoV.</td>
</tr>
<tr><td>Revisiting unknown RFID tag identification in large-scale internet of things</td>
<td align="right">2016</td>
<td>RFID is a major prerequisite for the IoT, which connects physical objects with the Internet. Unknown tag identification is a fundamental problem in large-scale IoT systems, such as automatic stock management and object tracking. Recently, several protocols have been proposed to discern unknown tags. In this article, we overview the underlying mechanism of previous protocols, and pinpoint the challenging issues together with possible solutions. Then we propose a scheme using a Bloom filter that significantly reduces the data transmission during the identification process. We further present the preliminary results to illuminate the Bloom-filter- based architecture.</td>
</tr>
<tr><td>MongoDB-Based Repository Design for IoT-Generated RFID/Sensor Big Data</td>
<td align="right">2016</td>
<td>Internet of Things (IoT)-generated data are characterized by its continuous generation, large amount, and unstructured format. The existing relational database technologies are inadequate to handle such IoT-generated data due to the limited processing speed and the significant storage-expansion cost. Thus, big data processing technologies, which are normally based on distributed file systems, distributed database management, and parallel processing technologies, have arisen as a core technology to implement IoT-generated data repositories. In this paper, we propose a sensor-integrated radio frequency identification (RFID) data repository-implementation model using MongoDB, the most popular big data-savvy document-oriented database system now. First, we devise a data repository schema that can effectively integrate and store the heterogeneous IoT data sources, such as RFID, sensor, and GPS, by extending the event data types in electronic product code information services standard, a de facto standard for the information exchange services for RFID-based traceability. Second, we propose an effective shard key to maximize query speed and uniform data distribution over data servers. Last, through a series of experiments measuring query speed and the level of data distribution, we show that the proposed design strategy, which is based on horizontal data partitioning and a compound shard key, is effective and efficient for the IoT-generated RFID/sensor big data.</td>
</tr>
<tr><td>Enabling a Smart City Application Ecosystem: Requirements and Architectural Aspects</td>
<td align="right">2016</td>
<td>Cities are becoming increasingly &quot;smart,&quot; but they need an underlying foundation that handles and manages all the lower-level complexities. In this article, the authors discuss relevant challenges and building blocks of a Smart City Application Ecosystem (SCALE).</td>
</tr>
<tr><td>Coalition Games for Spatio-Temporal Big Data in Internet of Vehicles Environment: A Comparative Analysis</td>
<td align="right">2015</td>
<td>The evolution of Internet of Things (IoT) leads to the emergence of Internet of Vehicles (IoV). In IoV, nodes/vehicles are connected with one another to form a vehicular ad hoc network (VANET). But, due to constant topological changes, database repository (centralized/distributed) in IoV is of spatio-temporal nature, as it contains traffic-related data, which is dependent on time and location from a large number of inter-connected vehicles. The nature of collected data varies in size, volume, and dimensions with the passage of time, which requires large storage and computation time for processing. So, one of the biggest challenges in IoV is to process this large volume of data and later on deliver to its destination with the help of a set of the intermediate/relay nodes. The intermediate/relay nodes may act either in cooperative or non-cooperative mode for processing the spatio-temporal data. This paper analyze this problem using Bayesian coalition game (BCG) and learning automata (LA). The LA stationed on the vehicles are assumed as the players in the game. For each action performed by an automaton, it may get a reward or a penalty from the environment using which each automaton updates its action probability vector for all the actions to be taken in future. A detailed comparison has been provided by analyzing the cooperative and noncooperative nature of the players in the game. The existence of Nash equilibrium (NE) with respect to the probabilistic belief of the strategies of the other players in the coalition game is also analyzed.</td>
</tr>
<tr><td>Analyzing Assisted Offloading of Cellular User Sessions onto D2D Links in Unlicensed Bands</td>
<td align="right">2015</td>
<td>For the past years, the analysts have been predicting a tremendous and continuous increase in mobile traffic, causing much of industry and academia to seek out any and all methods to increase wireless network capacity. In this paper, we investigate one such method, cellular data offloading onto direct connections between proximate user devices, which has been shown to provide significant wireless capacity gains. To do so, we formulate a new system model that couples a cellular network in licensed bands and a device-to-device (D2D) network in unlicensed bands. We propose that devices be continually associated with the cellular base station and use this connectivity to help manage their direct connections in unlicensed spectrum. In particular, we demonstrate that assisted offloading of cellular user sessions onto the D2D links improves the degree of spatial reuse and reduces the impact of interference. In this study, a session is a real-time flow of data from one user to another, which adheres to a Poisson point process (PPP). By contrast to a throughput- or capacity-centric system view, the application of PPP enables formulations where entire user sessions, rather than singular data packets, are arriving at random and leaving the system after being served. The proposed methodology is flexible enough to accommodate practical offloading scenarios, network selection algorithms, quality of service measures, and advanced wireless technologies. In this study, we are primarily interested in evaluating the data session blocking probability in dynamically loaded cellular and D2D networks, but given the importance of energy efficiency for mobile devices, we are also interested in characterizing the energy expenditure of a typical data session in these different networks. First with our advanced analytical methodology and then with our detailed system-level simulator, we evaluate the performance of network-assisted data session offloading from cellular to D2D connections under a variety of conditions. This analysis represents a useful tool in the development of practical offloading schemes and ongoing standardization efforts.</td>
</tr>
<tr><td>Live Data Analytics With Collaborative Edge and Cloud Processing in Wireless IoT Networks</td>
<td align="right">2017</td>
<td>Recently, big data analytics has received important attention in a variety of application domains including business, finance, space science, healthcare, telecommunication and Internet of Things (IoT). Among these areas, IoT is considered as an important platform in bringing people, processes, data and things/objects together in order to enhance the quality of our everyday lives. However, the key challenges are how to effectively extract useful features from the massive amount of heterogeneous data generated by resource-constrained IoT devices in order to provide real-time information and feedback to the end-users, and how to utilize this data-aware intelligence in enhancing the performance of wireless IoT networks. Although there are parallel advances in cloud computing and edge computing for addressing some issues in data analytics, they have their own benefits and limitations. The convergence of these two computing paradigms, i.e., massive virtually shared pool of computing and storage resources from the cloud and real-time data processing by edge computing, could effectively enable live data analytics in wireless IoT networks. In this regard, we propose a novel framework for coordinated processing between edge and cloud computing/processing by integrating advantages from both the platforms. The proposed framework can exploit the network-wide knowledge and historical information available at the cloud center to guide edge computing units towards satisfying various performance requirements of heterogeneous wireless IoT networks. Starting with the main features, key enablers and the challenges of big data analytics, we provide various synergies and distinctions between cloud and edge processing. More importantly, we identify and describe the potential key enablers for the proposed edge-cloud collaborative framework, the associated key challenges and some interesting future research directions.</td>
</tr>
<tr><td>An Efficient Small Data Transmission Scheme in the 3GPP NB-IoT System</td>
<td align="right">2017</td>
<td>This letter proposes an efficient small data transmission scheme in the narrow band (NB)-Internet of Things (IoT) system. For the efficient use of radio resources, the proposed scheme enables devices in an idle state to transmit a small data packet without the radio resource control connection setup process. This can improve the maximum number of supportable devices in the NB-IoT system which has insufficient radio resources. Numerical results have shown that the proposed scheme can increase the maximum number of supportable devices by about 60% compared with the conventional scheme.</td>
</tr>
<tr><td>Learning How to Communicate in the Internet of Things: Finite Resources and Heterogeneity</td>
<td align="right">2016</td>
<td>For a seamless deployment of the Internet of Things (IoT), there is a need for self-organizing solutions to overcome key IoT challenges that include data processing, resource management, coexistence with existing wireless networks, and improved IoT-wide event detection. One of the most promising solutions to address these challenges is via the use of innovative learning frameworks that will enable the IoT devices to operate autonomously in a dynamic environment. However, developing learning mechanisms for the IoT requires coping with unique IoT properties in terms of resource constraints, heterogeneity, and strict quality-of-service requirements. In this paper, a number of emerging learning frameworks suitable for IoT applications are presented. In particular, the advantages, limitations, IoT applications, and key results pertaining to machine learning, sequential learning, and reinforcement learning are studied. For each type of learning, the computational complexity, required information, and learning performance are discussed. Then, to handle the heterogeneity of the IoT, a new framework based on the powerful tools of cognitive hierarchy theory is introduced. This framework is shown to efficiently capture the different IoT device types and varying levels of available resources among the IoT devices. In particular, the different resource capabilities of IoT devices are mapped to different levels of rationality in cognitive hierarchy theory, thus enabling the IoT devices to use different learning frameworks depending on their available resources. Finally, key results on the use of cognitive hierarchy theory in the IoT are presented.</td>
</tr>
<tr><td>Design and Implementation of LPWA-Based Air Quality Monitoring System</td>
<td align="right">2016</td>
<td>Increasing attention has been paid to air quality monitoring with a rapid development in industry and transportation applications in the modern society. However, the existing air quality monitoring systems cannot provide satisfactory spatial and temporal resolutions of the air quality information with low costs in real time. In this paper, we propose a new method to implement the air quality monitoring system based on state-of-the-art Internet-of-Things (IoT) techniques. In this system, portable sensors collect the air quality information timely, which is transmitted through a low power wide area network. All air quality data are processed and analyzed in the IoT cloud. The completed air quality monitoring system, including both hardware and software, is developed and deployed successfully in urban environments. Experimental results show that the proposed system is reliable in sensing the air quality, which helps reveal the change patterns of air quality to some extent.</td>
</tr>
<tr><td>Enabling Massive IoT in 5G and Beyond Systems: PHY Radio Frame Design Considerations</td>
<td align="right">2016</td>
<td>The parameters of physical layer radio frame for 5th generation (5G) mobile cellular systems are expected to be flexibly configured to cope with diverse requirements of different scenarios and services. This paper presents a frame structure and design, which is specifically targeting Internet of Things (IoT) provision in 5G wireless communication systems. We design a suitable radio numerology to support the typical characteristics, that is, massive connection density and small and bursty packet transmissions with the constraint of low-cost and low complexity operation of IoT devices. We also elaborate on the design of parameters for random access channel enabling massive connection requests by IoT devices to support the required connection density. The proposed design is validated by link level simulation results to show that the proposed numerology can cope with transceiver imperfections and channel impairments. Furthermore, the results are also presented to show the impact of different values of guard band on system performance using different subcarrier spacing sizes for data and random access channels, which show the effectiveness of the selected waveform and guard bandwidth. Finally, we present system-level simulation results that validate the proposed design under realistic cell deployments and inter-cell interference conditions.</td>
</tr>
<tr><td>Foggy clouds and cloudy fogs: a real need for coordinated management of fog-to-cloud computing systems</td>
<td align="right">2016</td>
<td>The recent advances in cloud services technology are fueling a plethora of information technology innovation, including networking, storage, and computing. Today, various flavors have evolved of IoT, cloud computing, and so-called fog computing, a concept referring to capabilities of edge devices and users&#39; clients to compute, store, and exchange data among each other and with the cloud. Although the rapid pace of this evolution was not easily foreseeable, today each piece of it facilitates and enables the deployment of what we commonly refer to as a smart scenario, including smart cities, smart transportation, and smart homes. As most current cloud, fog, and network services run simultaneously in each scenario, we observe that we are at the dawn of what may be the next big step in the cloud computing and networking evolution, whereby services might be executed at the network edge, both in parallel and in a coordinated fashion, as well as supported by the unstoppable technology evolution. As edge devices become richer in functionality and smarter, embedding capacities such as storage or processing, as well as new functionalities, such as decision making, data collection, forwarding, and sharing, a real need is emerging for coordinated management of fog-to-cloud (F2C) computing systems. This article introduces a layered F2C architecture, its benefits and strengths, as well as the arising open and research challenges, making the case for the real need for their coordinated management. Our architecture, the illustrative use case presented, and a comparative performance analysis, albeit conceptual, all clearly show the way forward toward a new IoT scenario with a set of existing and unforeseen services provided on highly distributed and dynamic compute, storage, and networking resources, bringing together heterogeneous and commodity edge devices, emerging fogs, as well as conventional clouds.</td>
</tr>
<tr><td>Processing Distributed Internet of Things Data in Clouds</td>
<td align="right">2015</td>
<td>In the fifth installment of &quot;Blue Skies&quot; the authors discuss the capabilities and limitations of big data technologies as regards to collecting and analyzing distributed big data sets across multiple datacenters. The need to process distributed big data sets across multiple datacenters arises from the new breed of Internet of Things (IoT) applications.</td>
</tr>
<tr><td>Multiobjective Optimization for Computation Offloading in Fog Computing</td>
<td align="right">2018</td>
<td>Fog computing system is an emergent architecture for providing computing, storage, control, and networking capabilities for realizing Internet of Things. In the fog computing system, the mobile devices (MDs) can offload its data or computational expensive tasks to the fog node within its proximity, instead of distant cloud. Although offloading can reduce energy consumption at the MDs, it may also incur a larger execution delay including transmission time between the MDs and the fog/cloud servers, and waiting and execution time at the servers. Therefore, how to balance the energy consumption and delay performance is of research importance. Moreover, based on the energy consumption and delay, how to design a cost model for the MDs to enjoy the fog and cloud services is also important. In this paper, we utilize queuing theory to bring a thorough study on the energy consumption, execution delay, and payment cost of offloading processes in a fog computing system. Specifically, three queuing models are applied, respectively, to the MD, fog, and cloud centers, and the data rate and power consumption of the wireless link are explicitly considered. Based on the theoretical analysis, a multiobjective optimization problem is formulated with a joint objective to minimize the energy consumption, execution delay, and payment cost by finding the optimal offloading probability and transmit power for each MD. Extensive simulation studies are conducted to demonstrate the effectiveness of the proposed scheme and the superior performance over several existed schemes are observed.</td>
</tr>
<tr><td>A Semantic IoT Early Warning System for Natural Environment Crisis Management</td>
<td align="right">2015</td>
<td>An early warning system (EWS) is a core type of data driven Internet of Things (IoTs) system used for environment disaster risk and effect management. The potential benefits of using a semantic-type EWS include easier sensor and data source plug-and-play, simpler, richer, and more dynamic metadata-driven data analysis and easier service interoperability and orchestration. The challenges faced during practical deployments of semantic EWSs are the need for scalable time-sensitive data exchange and processing (especially involving heterogeneous data sources) and the need for resilience to changing ICT resource constraints in crisis zones. We present a novel IoT EWS system framework that addresses these challenges, based upon a multisemantic representation model. We use lightweight semantics for metadata to enhance rich sensor data acquisition. We use heavyweight semantics for top level W3C Web Ontology Language ontology models describing multileveled knowledge-bases and semantically driven decision support and workflow orchestration. This approach is validated through determining both system related metrics and a case study involving an advanced prototype system of the semantic EWS, integrated with a deployed EWS infrastructure.</td>
</tr>
<tr><td>Achieving Efficient and Secure Data Acquisition for Cloud-Supported Internet of Things in Smart Grid</td>
<td align="right">2017</td>
<td>Cloud-supported Internet of Things (Cloud-IoT) has been broadly deployed in smart grid systems. The IoT front-ends are responsible for data acquisition and status supervision, while the substantial amount of data is stored and managed in the cloud server. Achieving data security and system efficiency in the data acquisition and transmission process are of great significance and challenging, because the power grid-related data is sensitive and in huge amount. In this paper, we present an efficient and secure data acquisition scheme based on ciphertext policy attribute-based encryption. Data acquired from the terminals will be partitioned into blocks and encrypted with its corresponding access subtree in sequence, thereby the data encryption and data transmission can be processed in parallel. Furthermore, we protect the information about the access tree with threshold secret sharing method, which can preserve the data privacy and integrity from users with the unauthorized sets of attributes. The formal analysis demonstrates that the proposed scheme can fulfill the security requirements of the Cloud-IoT in smart grid. The numerical analysis and experimental results indicate that our scheme can effectively reduce the time cost compared with other popular approaches.</td>
</tr>
<tr><td>Joint Beamforming and Power-Splitting Control in Downlink Cooperative SWIPT NOMA Systems</td>
<td align="right">2017</td>
<td>This paper investigates the application of simultaneous wireless information and power transfer (SWIPT) to cooperative non-orthogonal multiple access (NOMA). A new cooperative multiple-input single-output (MISO) SWIPT NOMA protocol is proposed, where a user with a strong channel condition acts as an energy-harvesting (EH) relay by adopting power splitting (PS) scheme to help a user with a poor channel condition. By jointly optimizing the PS ratio and the beamforming vectors, we aim at maximizing the data rate of the “strong user” while satisfying the QoS requirement of the “weak user”. To resolve the formulated nonconvex problem, the semidefinite relaxation (SDR) technique is applied to reformulate the original problem, by proving the rank-one optimality. And then an iterative algorithm based on successive convex approximation (SCA) is proposed for complexity reduction, which can at least attain its stationary point efficiently. In view of the potential application scenarios, e.g., Internet of Things (IoT), the single-input single-output (SISO) case is also studied. The formulated problem is proved to be strictly unimodal with respect to the PS ratio. Hence, a golden section search (GSS) based algorithm with closed-form solution at each step is proposed to find the unique global optimal solution. It is worth pointing out that the SCA method can also converge to the optimal solution in SISO cases. In the numerical simulation, the proposed algorithm is numerically shown to converge within a few iterations, and the SWIPT-aided NOMA protocol outperforms the existing transmission protocols.</td>
</tr>
<tr><td>Spatiotemporal Stochastic Modeling of IoT Enabled Cellular Networks: Scalability and Stability Analysis</td>
<td align="right">2017</td>
<td>The Internet of Things (IoT) is large scale by nature, which is manifested by the massive number of connected devices as well as their vast spatial existence. Cellular networks, which provide ubiquitous, reliable, and efficient wireless access, will play fundamental rule in delivering the first-mile access for the data tsunami to be generated by the IoT. However, cellular networks may have scalability problems to provide uplink connectivity to massive numbers of connected things. To characterize the scalability of cellular uplink in the context of IoT networks, this paper develops a traffic-aware spatiotemporal mathematical model for IoT devices supported by cellular uplink connectivity. The developed model is based on stochastic geometry and queueing theory to account for the traffic requirement per IoT device, the different transmission strategies, and the mutual interference between the IoT devices. To this end, the developed model is utilized to characterize the extent to which cellular networks can accommodate IoT traffic as well as to assess and compare three different transmission strategies that incorporate a combination of transmission persistency, backoff, and power-ramping. The analysis and the results clearly illustrate the scalability problem imposed by IoT on cellular network and offer insights into effective scenarios for each transmission strategy.</td>
</tr>
<tr><td>Cooperative Fog Computing for Dealing with Big Data in the Internet of Vehicles: Architecture and Hierarchical Resource Management</td>
<td align="right">2017</td>
<td>As vehicle applications, mobile devices and the Internet of Things are growing fast, and developing an efficient architecture to deal with the big data in the Internet of Vehicles (IoV) has been an important concern for the future smart city. To overcome the inherent defect of centralized data processing in cloud computing, fog computing has been proposed by offloading computation tasks to local fog servers (LFSs). By considering factors like latency, mobility, localization, and scalability, this article proposes a regional cooperative fog-computing-based intelligent vehicular network (CFC-IoV) architecture for dealing with big IoV data in the smart city. Possible services for IoV applications are discussed, including mobility control, multi-source data acquisition, distributed computation and storage, and multi-path data transmission. A hierarchical model with intra-fog and inter-fog resource management is presented, and energy efficiency and packet dropping rates of LFSs in CFC-IoV are optimized.</td>
</tr>
<tr><td>IoT-Enabled Real-Time Production Performance Analysis and Exception Diagnosis Model</td>
<td align="right">2016</td>
<td>The recent developments of technologies in Internet of Things (IoT) provide the opportunities for smart manufacturing with real-time traceability, visibility, and interoperability in production planning, execution, and control. To fulfill this target, this work presents a real-time production performance analysis and exception diagnosis model (PAEDM). By this model, hierarchical-timed-colored Petri net (HTCPN) with smart tokens that change just like smart objects in practice is used to analyze the sensor data such that the critical performance information can be perceived. Decision Tree is used to diagnose exceptions from the critical production performance, so that persuasive qualitative and quantitative exception information can be extracted accurately. The presented method is demonstrated by a case study and simulation results show that PAEDM can be used to effectively analyze production performance and exceptions in real-time for dynamic and stochastic manufacturing processes.</td>
</tr>
<tr><td>A Cloud-Based Architecture for the Internet of Spectrum Devices Over Future Wireless Networks</td>
<td align="right">2016</td>
<td>The dramatic increase in data rates in wireless networks has caused radio spectrum usage to be an essential and critical issue. Spectrum sharing is widely recognized as an affordable, near-term method to address this issue. This paper first characterizes the new features of spectrum sharing in future wireless networks, including heterogeneity in sharing bands, diversity in sharing patterns, crowd intelligence in sharing devices, and hyperdensification in sharing networks. Then, to harness the benefits of these unique features and promote a vision of spectrum without bounds and networks without borders, this paper introduces a new concept of the Internet of spectrum devices (IoSDs) and develops a cloud-based architecture for IoSD over future wireless networks, with the prime aim of building a bridging network among various spectrum monitoring devices and massive spectrum utilization devices, and enabling a highly efficient spectrum sharing and management paradigm for future wireless networks. Furthermore, this paper presents a systematic tutorial on the key enabling techniques of the IoSD, including big spectrum data analytics, hierarchal spectrum resource optimization, and quality of experience-oriented spectrum service evaluation. In addition, the unresolved research issues are also presented.</td>
</tr>
<tr><td>Internet of Things and Edge Cloud Computing Roadmap for Manufacturing</td>
<td align="right">2016</td>
<td>The manufacturing industry is exploring the use of Internet of Things and cloud computing to enhance the efficiency of manufacturing plant operations, improve product quality, increase manufacturers&#39; ability to respond to changing customer demands, and expand to new markets. Productivity, quality, safety, and the ability to respond quickly to changing conditions are essential to maintaining the industry&#39;s competitiveness.</td>
</tr>
<tr><td>Standards-Based Worldwide Semantic Interoperability for IoT</td>
<td align="right">2016</td>
<td>Global IoT services (GIoTS) are combining locally available IoT resources with cloud-based services. They are targeting worldwide services. GIoTS require interoperability between the locally installed heterogeneous IoT systems. Semantic processing is an important technology to enable data mediation as well as knowledge-based processing. This article explains a system architecture for achieving worldwide semantic interoperability using international standards such as oneM2M and the OMA NGSI-9/10 context interfaces (as used in the European Future Internet Platform FIWARE). Semantics also enables the use of knowledge-based semantic processing agents. Furthermore, we explain how semantic verification enables the testing of such complex systems.</td>
</tr>
<tr><td>A Hybrid Approach to Clustering in Big Data</td>
<td align="right">2016</td>
<td>Clustering of big data has received much attention recently. In this paper, we present a new clusiVAT algorithm and compare it with four other popular data clustering algorithms. Three of the four comparison methods are based on the well known, classical batch k-means model. Specifically, we use k-means, single pass k-means, online k-means, and clustering using representatives (CURE) for numerical comparisons. clusiVAT is based on sampling the data, imaging the reordered distance matrix to estimate the number of clusters in the data visually, clustering the samples using a relative of single linkage (SL), and then noniteratively extending the labels to the rest of the data-set using the nearest prototype rule. Previous work has established that clusiVAT produces true SL clusters in compact-separated data. We have performed experiments to show that k-means and its modified algorithms suffer from initialization issues that cause many failures. On the other hand, clusiVAT needs no initialization, and almost always finds partitions that accurately match ground truth labels in labeled data. CURE also finds SL type partitions but is much slower than the other four algorithms. In our experiments, clusiVAT proves to be the fastest and most accurate of the five algorithms; e.g., it recovers 97% of the ground truth labels in the real world KDD-99 cup data (4292637 samples in 41 dimensions) in 76 s.</td>
</tr>
<tr><td>Fog Computing for the Internet of Things: Security and Privacy Issues</td>
<td align="right">2017</td>
<td>The inherent characteristics of Internet of Things (IoT) devices, such as limited storage and computational power, require a new platform to efficiently process data. The concept of fog computing has been introduced as a technology to bridge the gap between remote data centers and IoT devices. Fog computing enables a wide range of benefits, including enhanced security, decreased bandwidth, and reduced latency. These benefits make the fog an appropriate paradigm for many IoT services in various applications such as connected vehicles and smart grids. Nevertheless, fog devices (located at the edge of the Internet) obviously face many security and privacy threats, much the same as those faced by traditional data centers. In this article, the authors discuss the security and privacy issues in IoT environments and propose a mechanism that employs fog to improve the distribution of certificate revocation information among IoT devices for security enhancement. They also present potential research directions aimed at using fog computing to enhance the security and privacy issues in IoT environments.</td>
</tr>
<tr><td>The Promise of Edge Computing</td>
<td align="right">2016</td>
<td>The success of the Internet of Things and rich cloud services have helped create the need for edge computing, in which data processing occurs in part at the network edge, rather than completely in the cloud. Edge computing could address concerns such as latency, mobile devices&#39; limited battery life, bandwidth costs, security, and privacy.</td>
</tr>
<tr><td>An Efficient File Hierarchy Attribute-Based Encryption Scheme in Cloud Computing</td>
<td align="right">2016</td>
<td>Ciphertext-policy attribute-based encryption (CP-ABE) has been a preferred encryption technology to solve the challenging problem of secure data sharing in cloud computing. The shared data files generally have the characteristic of multilevel hierarchy, particularly in the area of healthcare and the military. However, the hierarchy structure of shared files has not been explored in CP-ABE. In this paper, an efficient file hierarchy attribute-based encryption scheme is proposed in cloud computing. The layered access structures are integrated into a single access structure, and then, the hierarchical files are encrypted with the integrated access structure. The ciphertext components related to attributes could be shared by the files. Therefore, both ciphertext storage and time cost of encryption are saved. Moreover, the proposed scheme is proved to be secure under the standard assumption. Experimental simulation shows that the proposed scheme is highly efficient in terms of encryption and decryption. With the number of the files increasing, the advantages of our scheme become more and more conspicuous.</td>
</tr>
<tr><td>Mobile Services for Customization Manufacturing Systems: An Example of Industry 4.0</td>
<td align="right">2016</td>
<td>In the context of Industry 4.0, it is necessary to meet customization manufacturing demands on a timely basis. Based on the related concepts of Industry 4.0, this paper intends to introduce mobile services and cloud computing technology into the intelligent manufacturing environment. A customization manufacturing system is designed to meet the demands of personalization requests and flexible production mechanisms. This system consists of three layers, namely, a manufacturing device layer, cloud service system layer, and mobile service layer. The manufacturing device layer forms the production platform. This platform is composed of a number of physical devices, such as a flexible conveyor belt, industrial robots, and corresponding sensors. The physical devices are connected to the cloud via the support of a wireless module. In the cloud, the manufacturing big data are processed, and the optimization decision-making mechanism pertaining to customization manufacturing is formed. Then, mobile services running in a mobile terminal are used to receive orders from customers and to inquire the necessary production information. To verify the feasibility of the proposed customization manufacturing system, we also established a customizable candy production system.</td>
</tr>
<tr><td>Learning IoT in Edge: Deep Learning for the Internet of Things with Edge Computing</td>
<td align="right">2018</td>
<td>Deep learning is a promising approach for extracting accurate information from raw sensor data from IoT devices deployed in complex environments. Because of its multilayer structure, deep learning is also appropriate for the edge computing environment. Therefore, in this article, we first introduce deep learning for IoTs into the edge computing environment. Since existing edge nodes have limited processing capability, we also design a novel offloading strategy to optimize the performance of IoT deep learning applications with edge computing. In the performance evaluation, we test the performance of executing multiple deep learning tasks in an edge computing environment with our strategy. The evaluation results show that our method outperforms other optimization solutions on deep learning for IoT.</td>
</tr>
<tr><td>Large System Secrecy Rate Analysis for SWIPT MIMO Wiretap Channels</td>
<td align="right">2016</td>
<td>In this paper, we study the multiple-input multiple-output wiretap channel for simultaneous wireless information and power transfer, in which there is a base station (BS), an information-decoding (ID) user, and an energy-harvesting (EH) user. The messages intended to the ID user is required to be kept confidential to the EH user. Our objective is to design the optimal transmit covariance matrix at the BS for maximizing the ergodic secrecy rate subject to the harvested energy requirement for the EH user exploiting only statistical channel state information at the BS. To this end, we begin by deriving an approximation for the ergodic secrecy rate using large-dimensional random matrix theory and the method of Taylor series expansion. This approximation enables us to derive the asymptotic-optimal transmit covariance matrix that achieves the tradeoff for ergodic secrecy rate and harvested energy. The simulation results are provided to verify the accuracy of the approximation and show that a bigger rate-energy region can be achieved when the Rician factor increases or the path loss exponent decreases. We also show that when the transmit correlation increases or the distance between the eavesdropper and the BS decreases, the harvested energy will be increased, while the achieved ergodic secrecy rate decreases.</td>
</tr>
<tr><td>A Lightweight Privacy-Preserving Data Aggregation Scheme for Fog Computing-Enhanced IoT</td>
<td align="right">2017</td>
<td>Fog computing-enhanced Internet of Things (IoT) has recently received considerable attention, as the fog devices deployed at the network edge can not only provide low latency, location awareness but also improve real-time and quality of services in IoT application scenarios. Privacy-preserving data aggregation is one of typical fog computing applications in IoT, and many privacy-preserving data aggregation schemes have been proposed in the past years. However, most of them only support data aggregation for homogeneous IoT devices, and cannot aggregate hybrid IoT devices&#39; data into one in some real IoT applications. To address this challenge, in this paper, we present a lightweight privacy-preserving data aggregation scheme, called Lightweight Privacy-preserving Data Aggregation, for fog computing-enhanced IoT. The proposed LPDA is characterized by employing the homomorphic Paillier encryption, Chinese Remainder Theorem, and one-way hash chain techniques to not only aggregate hybrid IoT devices&#39; data into one, but also early filter injected false data at the network edge. Detailed security analysis shows LPDA is really secure and privacy-enhanced with differential privacy techniques. In addition, extensive performance evaluations are conducted, and the results indicate LPDA is really lightweight in fog computing-enhanced IoT.</td>
</tr>
</tbody></table>
</div></div></div>